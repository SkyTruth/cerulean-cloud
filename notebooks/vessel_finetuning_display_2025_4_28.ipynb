{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set the download path for demonstration and ensure the folder exists.\n",
    "download_path = os.getenv(\"ASA_DOWNLOAD_PATH\")\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "git_path = os.getenv(\"GIT_FOLDER\")\n",
    "cv3_path = os.getenv(\"CV3_FOLDER\")\n",
    "sys.path.append(git_path)\n",
    "sys.path.append(cv3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerulean_cloud.cloud_function_asa.utils.analyzer import AISAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from your script.\n",
    "from asa_analysis.evaluation.source_analyzer_evaluation import (\n",
    "    label_results_with_st_name,\n",
    "    apply_labeling,\n",
    "    calculate_metrics,\n",
    "    plot_metrics,\n",
    "    process_groundtruth_on_analyzer,\n",
    "    add_missing_groundtruth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3_gdfs(gdf1, gdf2, gdf3, figsize=(10, 10), title=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if not isinstance(gdf1, type(None)):\n",
    "        gdf1.plot(ax=ax, color=\"blue\", alpha=0.5, edgecolor=\"black\")\n",
    "    if not isinstance(gdf2, type(None)):\n",
    "        gdf2.plot(ax=ax, color=\"red\", edgecolor=\"red\", linestyle=\"--\")\n",
    "    if not isinstance(gdf3, type(None)):\n",
    "        gdf3.plot(ax=ax, color=\"green\", alpha=1.0, edgecolor=\"black\", marker=\"o\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hitl CSV for vessel and infrastructure groundtruth.\n",
    "csv_path = r\"../slick_to_source_2025-3-20.csv\"\n",
    "hitl_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract groundtruth lists for infrastructure and vessels.\n",
    "infrastructure_groundtruth = hitl_df[\n",
    "    (hitl_df[\"type\"] == 2) & (hitl_df[\"hitl_verification\"])\n",
    "]\n",
    "vessel_groundtruth = hitl_df[(hitl_df[\"type\"] == 1) & (hitl_df[\"hitl_verification\"])]\n",
    "\n",
    "if \"slick\" in vessel_groundtruth.columns:\n",
    "    vessel_groundtruth = vessel_groundtruth.rename(columns={\"slick\": \"slick_id\"})\n",
    "if \"slick\" in infrastructure_groundtruth.columns:\n",
    "    infrastructure_groundtruth = infrastructure_groundtruth.rename(\n",
    "        columns={\"slick\": \"slick_id\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results_files = os.listdir(\"saves/buffer_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_results = {}\n",
    "for file in finetuned_results_files:\n",
    "    f_list = file[:-4].split(\"_\")\n",
    "    b_a_buff = f_list[2] + \", \" + f_list[3] + \", \" + f_list[4]\n",
    "    res = pd.read_csv(f\"saves/buffer_finetuning/{file}\")\n",
    "    res[\"st_name\"] = res[\"st_name\"].astype(int)\n",
    "    res_labelled = apply_labeling(res, vessel_groundtruth, label_results_with_st_name)\n",
    "    res_labelled = add_missing_groundtruth(res_labelled, vessel_groundtruth)\n",
    "    buffer_results[b_a_buff] = res_labelled\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = calculate_metrics(buffer_results)\n",
    "plot_metrics(\n",
    "    metrics_df,\n",
    "    title=\"HOURS_BEFORE, HOURS_AFTER, AIS_BUFFER:\",\n",
    "    legend_title=\"Before, After, Buffer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results_files2 = [\n",
    "    \"vessel_results_1_1_20000.csv\",\n",
    "    \"vessel_results_4_2_20000.csv\",\n",
    "    \"vessel_results_6_4_20000.csv\",\n",
    "    \"vessel_results_8_4_20000.csv\",\n",
    "    \"vessel_results_8_6_20000.csv\",\n",
    "    \"vessel_results_9_5_20000.csv\",\n",
    "    \"vessel_results_10_4_20000.csv\",\n",
    "    \"vessel_results_10_6_20000.csv\",\n",
    "    \"vessel_results_12_6_20000.csv\",\n",
    "    \"vessel_results_14_8_20000.csv\",\n",
    "    \"vessel_results_16_8_20000.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [\n",
    "    file[:-4].split(\"_\")[2] + \", \" + file[:-4].split(\"_\")[3]\n",
    "    for file in finetuned_results_files2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_after_results = {}\n",
    "for file in finetuned_results_files2:\n",
    "    f_list = file[:-4].split(\"_\")\n",
    "    b_a_buff = f_list[2] + \", \" + f_list[3] + \", \" + f_list[4]\n",
    "    res = pd.read_csv(f\"saves/before_after_finetuning/{file}\")\n",
    "    res[\"st_name\"] = res[\"st_name\"].astype(int)\n",
    "    res_labelled = apply_labeling(res, vessel_groundtruth, label_results_with_st_name)\n",
    "    res_labelled = add_missing_groundtruth(res_labelled, vessel_groundtruth)\n",
    "    before_after_results[b_a_buff] = res_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = calculate_metrics(before_after_results)\n",
    "plot_metrics(\n",
    "    metrics_df,\n",
    "    title=\"HOURS_BEFORE, HOURS_AFTER, AIS_BUFFER:\",\n",
    "    legend_title=\"Before, After, Buffer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = [g.iloc[0][\"runtime\"] for i, g in before_after_results.items()]\n",
    "plt.plot(intervals, runtimes)\n",
    "plt.xlabel(\"Intervals\")\n",
    "plt.ylabel(\"Runtime\")\n",
    "plt.title(\"Runtime vs Intervals\")  # Optional, adds a title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_a_buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreads = [1, 100, 1000, 2000, 5000, 7500, 10000, 15000, 20000, 50000, 100000]\n",
    "spread_results = {}\n",
    "for spread in spreads:\n",
    "    res = pd.read_csv(f\"saves/spread_finetuning/vessel_results_spread_8_6_{spread}.csv\")\n",
    "    res[\"st_name\"] = res[\"st_name\"].astype(int)\n",
    "    res_labelled = apply_labeling(res, vessel_groundtruth, label_results_with_st_name)\n",
    "    res_labelled = add_missing_groundtruth(res_labelled, vessel_groundtruth)\n",
    "    spread_results[str(spread)] = res_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_labelled[res_labelled[\"truth\"]])\n",
    "res_labelled[res_labelled[\"truth\"]][\n",
    "    res_labelled[res_labelled[\"truth\"]][\"coincidence_score\"] == 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "83 / 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = calculate_metrics(spread_results)\n",
    "plot_metrics(\n",
    "    metrics_df,\n",
    "    title=\"Metrics at different Spread Rates\",\n",
    "    legend_title=\"Before, After, Buffer\",\n",
    "    value_font_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slick_ids = vessel_groundtruth[\"slick_id\"].values\n",
    "slick_id = slick_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"hours_before\": 10, \"hours_after\": 6, \"ais_buffer\": 100}\n",
    "\n",
    "results_vessel_local, analyzer = process_groundtruth_on_analyzer(\n",
    "    AISAnalyzer,\n",
    "    vessel_groundtruth[vessel_groundtruth[\"slick_id\"] == slick_id],\n",
    "    analyzer_params=kwargs,\n",
    "    reuse_ais_gdf=True,\n",
    "    return_analyzer=True,\n",
    ")\n",
    "results_vessel_local[\"st_name\"] = results_vessel_local[\"st_name\"].astype(int)\n",
    "results_vessel_local = apply_labeling(\n",
    "    results_vessel_local, vessel_groundtruth, label_results_with_st_name\n",
    ")\n",
    "results_vessel_local = add_missing_groundtruth(results_vessel_local, vessel_groundtruth)\n",
    "# truth = results_vessel_local[results_vessel_local['truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graces = [1, 100, 500, 1000, 2500, 5000, 10000]\n",
    "grace_results = {}\n",
    "for grace in graces:\n",
    "    res = pd.read_csv(f\"saves/grace_finetuning/vessel_results_grace_{grace}.csv\")\n",
    "    res[\"st_name\"] = res[\"st_name\"].astype(int)\n",
    "    res_labelled = apply_labeling(res, vessel_groundtruth, label_results_with_st_name)\n",
    "    res_labelled = add_missing_groundtruth(res_labelled, vessel_groundtruth)\n",
    "    grace_results[str(grace)] = res_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = calculate_metrics(grace_results)\n",
    "plot_metrics(\n",
    "    metrics_df,\n",
    "    title=\"Metrics at different Grace Distances\",\n",
    "    legend_title=\"Before, After, Buffer\",\n",
    "    value_font_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifts = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "drift_results = {}\n",
    "for drift in drifts:\n",
    "    res = pd.read_csv(f\"saves/drift_finetuning/vessel_results_drift_{drift}.csv\")\n",
    "    res[\"st_name\"] = res[\"st_name\"].astype(int)\n",
    "    res_labelled = apply_labeling(res, vessel_groundtruth, label_results_with_st_name)\n",
    "    res_labelled = add_missing_groundtruth(res_labelled, vessel_groundtruth)\n",
    "    drift_results[str(drift)] = res_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = calculate_metrics(drift_results)\n",
    "plot_metrics(\n",
    "    metrics_df,\n",
    "    title=\"Metrics at different Max Slick Drifting Hours\",\n",
    "    legend_title=\"Before, After, Buffer\",\n",
    "    value_font_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = [g.iloc[0][\"runtime\"] for i, g in drift_results.items()]\n",
    "plt.plot(drifts, runtimes)\n",
    "plt.xlabel(\"Drift Parameter\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title(\"FULL ASA Runtime vs Drift Parameter\")  # Optional, adds a title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "71 / 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vessel_local"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
