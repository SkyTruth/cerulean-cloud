{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqXYtLmzgrRW"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, MultiPolygon, Polygon\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from types import SimpleNamespace\n",
    "from geoalchemy2 import WKTElement\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\ebeva\\SkyTruth\\git\\cerulean-cloud\")\n",
    "from cerulean_cloud.cloud_function_asa.utils.analyzer import InfrastructureAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46ZSjK76Xlki"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VersionedInfrastructureAnalyzer(InfrastructureAnalyzer):\n",
    "    def __init__(self, s1_scene, version=1, **kwargs):\n",
    "        # polygon_geom = [Polygon([(0, 0), (1, 1), (1, 0)])]\n",
    "        # s1_scene = gpd.GeoDataFrame(geometry=polygon_geom, crs=\"EPSG:4326\")\n",
    "        super().__init__(s1_scene, **kwargs)\n",
    "        self.version = version\n",
    "\n",
    "    def compute_coincidence_scores_for_infra(\n",
    "        self,\n",
    "        infra_gdf: gpd.GeoDataFrame,\n",
    "        extremity_tree: cKDTree,\n",
    "        all_extremity_points: np.ndarray,\n",
    "        all_weights: np.ndarray,\n",
    "        radius_of_interest: float,\n",
    "        decay_factor: float,\n",
    "        version: str = None,\n",
    "    ) -> np.ndarray:\n",
    "        if version is None:\n",
    "            version = self.version  # Use instance version if not provided\n",
    "\n",
    "        infra_coords = np.array([(geom.x, geom.y) for geom in infra_gdf.geometry])\n",
    "        extremity_indices = extremity_tree.query_ball_point(\n",
    "            infra_coords, r=radius_of_interest\n",
    "        )\n",
    "        coincidence_scores = np.zeros(len(infra_coords))\n",
    "\n",
    "        for i, neighbors in enumerate(extremity_indices):\n",
    "            if neighbors:\n",
    "                neighbor_points = all_extremity_points[neighbors]\n",
    "                neighbor_weights = all_weights[neighbors]\n",
    "                dists = np.linalg.norm(neighbor_points - infra_coords[i], axis=1)\n",
    "\n",
    "                # Compute C_i based on version\n",
    "                if self.version == 1:\n",
    "                    C_i = (\n",
    "                        neighbor_weights\n",
    "                        - self.decay_factor * dists / radius_of_interest\n",
    "                    )\n",
    "                elif self.version == 2:\n",
    "                    C_i = neighbor_weights * (\n",
    "                        1 - self.decay_factor * dists / radius_of_interest\n",
    "                    )\n",
    "                elif self.version == 3:\n",
    "                    C_i = neighbor_weights * np.exp(\n",
    "                        -self.decay_factor * dists / radius_of_interest\n",
    "                    )\n",
    "\n",
    "                coincidence_scores[i] = np.clip(C_i.max(), 0, 1)\n",
    "\n",
    "        return coincidence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s1_scene(scene_id, download_path=os.getenv(\"ASA_DOWNLOAD_PATH\")):\n",
    "    \"\"\"\n",
    "    Downloads a S1 scene GeoJSON file from the specified URL if it hasn't been downloaded already.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.cerulean.skytruth.org/collections/public.sentinel1_grd/items?scene_id={scene_id}&f=geojson\"\n",
    "    geojson_file_path = os.path.join(download_path, f\"{scene_id}.geojson\")\n",
    "    if not os.path.exists(geojson_file_path):\n",
    "        print(f\"Downloading GeoJSON file for Scene {scene_id}...\")\n",
    "        os.system(f'curl \"{url}\" -o \"{geojson_file_path}\"')\n",
    "        print(f\"Downloaded GeoJSON to {geojson_file_path}\")\n",
    "    else:\n",
    "        print(f\"GeoJSON file already exists at {geojson_file_path}. Skipping download.\")\n",
    "    s1_gdf = gpd.read_file(geojson_file_path)\n",
    "    # print(s1_gdf)\n",
    "    s1_scene = SimpleNamespace(\n",
    "        scene_id=scene_id,\n",
    "        scihub_ingestion_time=s1_gdf.scihub_ingestion_time.iloc[0],\n",
    "        start_time=s1_gdf.start_time.iloc[0],\n",
    "        end_time=s1_gdf.end_time.iloc[0],\n",
    "        geometry=WKTElement(str(s1_gdf.geometry.iloc[0])),\n",
    "    )\n",
    "    return s1_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNJULOg9y427"
   },
   "outputs": [],
   "source": [
    "def plot_metrics_by_decay(\n",
    "    decay_rates,\n",
    "    true_association_scores,\n",
    "    false_association_scores,\n",
    "    top_source_rate,\n",
    "    top_3_source_rate,\n",
    "    avg_max_score,\n",
    "    version=\"v1\",\n",
    "):\n",
    "    # Calculate True - False Association Scores\n",
    "    true_minus_false_scores = [\n",
    "        t - f for t, f in zip(true_association_scores, false_association_scores)\n",
    "    ]\n",
    "\n",
    "    # Set up the figure and subplots in a single row\n",
    "    plt.figure(figsize=(24, 6))\n",
    "\n",
    "    # Set the main title for the figure\n",
    "    plt.suptitle(\n",
    "        f\"Metrics by Decay Rate for version {version}\", fontsize=16, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "    # Generate positions for the decay rates (categorical x-axis)\n",
    "    x = np.arange(len(decay_rates))\n",
    "\n",
    "    # Subplot for True - False Association Scores by decay rate\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.plot(x, true_minus_false_scores, marker=\"o\", color=\"cornflowerblue\")\n",
    "    plt.xlabel(\"Decay Rate\")\n",
    "    plt.ylabel(\"True - False Association Scores\")\n",
    "    plt.title(\"Difference of Avg Source Score and Avg Non-Source Score\")\n",
    "    plt.xticks(x, decay_rates)\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(true_minus_false_scores):\n",
    "        plt.text(\n",
    "            i,\n",
    "            v + 0.01 if v >= 0 else v - 0.01,\n",
    "            f\"{v:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\" if v >= 0 else \"top\",\n",
    "        )\n",
    "\n",
    "    # Subplot for Top Source Rate by decay rate\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.plot(x, top_source_rate, marker=\"o\", color=\"gold\")\n",
    "    plt.xlabel(\"Decay Rate\")\n",
    "    plt.ylabel(\"Top Source Rate\")\n",
    "    plt.title(\"Top Source Rate by Decay Rate\")\n",
    "    plt.xticks(x, decay_rates)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, v in enumerate(top_source_rate):\n",
    "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Subplot for Top 3 Source Rate by decay rate\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.plot(x, top_3_source_rate, marker=\"o\", color=\"mediumseagreen\")\n",
    "    plt.xlabel(\"Decay Rate\")\n",
    "    plt.ylabel(\"Top 3 Source Rate\")\n",
    "    plt.title(\"Top 3 Source Rate by Decay Rate\")\n",
    "    plt.xticks(x, decay_rates)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, v in enumerate(top_3_source_rate):\n",
    "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Subplot for Avg Max Score by decay rate\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.plot(x, avg_max_score, marker=\"o\", color=\"purple\")\n",
    "    plt.xlabel(\"Decay Rate\")\n",
    "    plt.ylabel(\"Avg Max Score\")\n",
    "    plt.title(\"Avg Max Score of Non-Source by Decay Rate\")\n",
    "    plt.xticks(x, decay_rates)\n",
    "    plt.ylim(0, 0.5)\n",
    "    for i, v in enumerate(avg_max_score):\n",
    "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_plots(\n",
    "    true_association_scores,\n",
    "    false_association_scores,\n",
    "    top_source_rate,\n",
    "    top_3_source_rate,\n",
    "):\n",
    "    # Labels for versions and baseline\n",
    "    labels = [\"v1\", \"v2\", \"v3\", \"baseline\"]\n",
    "\n",
    "    # Define bar width and positions for each metric\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(labels))\n",
    "\n",
    "    # Calculate True minus False Association Scores\n",
    "    true_scores = [np.mean(scores) for scores in true_association_scores]\n",
    "    false_scores = [np.mean(scores) for scores in false_association_scores]\n",
    "    true_minus_false_scores = [t - f for t, f in zip(true_scores, false_scores)]\n",
    "\n",
    "    # Set up the figure and subplots in a single row\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Subplot for True - False Association Scores\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.bar(x, true_minus_false_scores, color=\"cornflowerblue\", width=bar_width)\n",
    "    plt.xlabel(\"Versions\")\n",
    "    plt.ylabel(\"True - False Association Scores\")\n",
    "    plt.title(\"Avg Source Score minus Avg non-source Score\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylim(0, 1.1)  # Set range from 0 to 1\n",
    "    for i, v in enumerate(true_minus_false_scores):\n",
    "        plt.text(\n",
    "            i,\n",
    "            v + 0.01 if v >= 0 else v - 0.01,\n",
    "            f\"{v:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\" if v >= 0 else \"top\",\n",
    "        )\n",
    "\n",
    "    # Subplot for Top Source Rate\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.bar(x, top_source_rate, color=\"gold\", width=bar_width)\n",
    "    plt.xlabel(\"Versions\")\n",
    "    plt.ylabel(\"Top Source Rate\")\n",
    "    plt.title(\"Top Source Rate by Version\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, v in enumerate(top_source_rate):\n",
    "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Subplot for Top 3 Source Rate\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.bar(x, top_3_source_rate, color=\"mediumseagreen\", width=bar_width)\n",
    "    plt.xlabel(\"Versions\")\n",
    "    plt.ylabel(\"Top 3 Source Rate\")\n",
    "    plt.title(\"Top 3 Source Rate by Version\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, v in enumerate(top_3_source_rate):\n",
    "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4r6jlBgRebF"
   },
   "outputs": [],
   "source": [
    "def point_to_polygon_probability(\n",
    "    points_gdf, polygons_gdf, decay_constant=200, buffer=0.025\n",
    "):\n",
    "    probabilities = np.zeros(len(points_gdf))\n",
    "    points_gdf[\"orig_index\"] = points_gdf.index\n",
    "\n",
    "    minx, miny, maxx, maxy = polygons_gdf.iloc[0].geometry.bounds\n",
    "    filtered_points = points_gdf[\n",
    "        (points_gdf.geometry.x >= minx - buffer)\n",
    "        & (points_gdf.geometry.x <= maxx + buffer)\n",
    "        & (points_gdf.geometry.y >= miny - buffer)\n",
    "        & (points_gdf.geometry.y <= maxy + buffer)\n",
    "    ]\n",
    "\n",
    "    for i, point in enumerate(filtered_points.geometry):\n",
    "        min_distance = float(\"inf\")\n",
    "        for polygon in polygons_gdf.geometry:\n",
    "            if isinstance(polygon, MultiPolygon):\n",
    "                distance = min(point.distance(part.exterior) for part in polygon.geoms)\n",
    "            elif isinstance(polygon, Polygon):\n",
    "                distance = point.distance(polygon.exterior)\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Polygon geometries must be either Polygon or MultiPolygon types.\"\n",
    "                )\n",
    "            min_distance = min(min_distance, distance)\n",
    "\n",
    "        probability = np.exp(-decay_constant * min_distance)\n",
    "        index = filtered_points.iloc[i][\"orig_index\"]\n",
    "        probabilities[index] = probability\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_proj_string(gdf):\n",
    "    # Calculate the centroid of the GeoDataFrame in latitude and longitude (EPSG:4326)\n",
    "    centroid = gdf.to_crs(\"EPSG:4326\").geometry.centroid\n",
    "\n",
    "    # Get the mean longitude to determine UTM zone\n",
    "    mean_longitude = centroid.x.mean()\n",
    "    mean_latitude = centroid.y.mean()\n",
    "\n",
    "    # Calculate UTM zone number\n",
    "    utm_zone = int((mean_longitude + 180) / 6) + 1\n",
    "\n",
    "    # Determine hemisphere\n",
    "    hemisphere = \"+north\" if mean_latitude >= 0 else \"+south\"\n",
    "\n",
    "    # Return PROJ string in UTM format\n",
    "    proj_string = f\"+proj=utm +zone={utm_zone} {hemisphere} +type=crs\"\n",
    "    return proj_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVy-UaJ2-pM5"
   },
   "outputs": [],
   "source": [
    "def calculate_associated_infra(groundtruth_slicks, gfw_gdf, asa, baseline=False):\n",
    "    associated_infra = []\n",
    "    for i in range(len(groundtruth_slicks)):\n",
    "        slick_of_interest = groundtruth_slicks.iloc[[i]]\n",
    "        # gfw_gdf = gfw_gdf.to_crs(asa.crs_meters)\n",
    "        if baseline:\n",
    "            probabilities = asa(gfw_gdf, slick_of_interest)\n",
    "            potential_sources = gfw_gdf[probabilities > 0]\n",
    "            potential_sources[\"coincidence_score\"] = probabilities[probabilities > 0]\n",
    "        else:\n",
    "            asa.crs_meters = get_utm_proj_string(slick_of_interest)\n",
    "            asa.s1_scene.scene_id = slick_of_interest[\"scene_id\"].values[0]\n",
    "            potential_sources = asa.compute_coincidence_scores(slick_of_interest)\n",
    "        # print(len(probabilities))\n",
    "        if isinstance(potential_sources, type(None)):\n",
    "            potential_sources = gpd.GeoDataFrame(\n",
    "                columns=[\"structure_id\", \"coincidence_score\"]\n",
    "            )\n",
    "        # print(probabilities)\n",
    "\n",
    "        potential_sources = potential_sources.sort_values(\n",
    "            by=\"coincidence_score\", ascending=False\n",
    "        )\n",
    "        associated_infra.append(potential_sources)\n",
    "    return associated_infra\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_false_score(associated_infra, groundtruth_slicks):\n",
    "    max_non_source_score = []\n",
    "    for i, potential_sources in enumerate(associated_infra):\n",
    "        false_association_scores = [0]\n",
    "        # Grab slick of interest and ground truth structure ids\n",
    "        slick_of_interest = groundtruth_slicks.iloc[[i]]\n",
    "        ground_truth_sources = [\n",
    "            int(structure_id)\n",
    "            for structure_id in slick_of_interest[\"structure_ids\"]\n",
    "            .values[0]\n",
    "            .strip(\"[]\")\n",
    "            .split(\",\")\n",
    "        ]\n",
    "\n",
    "        # Grab scores and gfw structure ids associated with slick\n",
    "        scores = potential_sources[\"coincidence_score\"].values\n",
    "        struct_ids = potential_sources[\"structure_id\"].values\n",
    "\n",
    "        # Grab the top potential source and record if it is a true or false source\n",
    "        # Record scores for true and false infra\n",
    "        for j, struct_id in enumerate(struct_ids):\n",
    "            if struct_id not in ground_truth_sources:\n",
    "                false_association_scores.append(scores[j])\n",
    "        max_non_source_score.append(max(false_association_scores))\n",
    "    return max_non_source_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-GfjQhRCnnD"
   },
   "outputs": [],
   "source": [
    "def scores_and_rates(associated_infra, groundtruth_slicks):\n",
    "    association_scores = []\n",
    "    top_source_rate = []\n",
    "    top_3_source_rate = []\n",
    "    total_sources = []\n",
    "\n",
    "    false_association_scores = []\n",
    "\n",
    "    for i, potential_sources in enumerate(associated_infra):\n",
    "        # Grab slick of interest and ground truth structure ids\n",
    "        slick_of_interest = groundtruth_slicks.iloc[[i]]\n",
    "        ground_truth_sources = [\n",
    "            int(structure_id)\n",
    "            for structure_id in slick_of_interest[\"structure_ids\"]\n",
    "            .values[0]\n",
    "            .strip(\"[]\")\n",
    "            .split(\",\")\n",
    "        ]\n",
    "\n",
    "        # Grab scores and gfw structure ids associated with slick\n",
    "        scores = potential_sources[\"coincidence_score\"].values\n",
    "        struct_ids = potential_sources[\"structure_id\"].values\n",
    "\n",
    "        # Grab the top potential source and record if it is a true or false source\n",
    "        top_source = struct_ids[0] if len(struct_ids) > 0 else None\n",
    "        top_source_rate.append(top_source in ground_truth_sources)\n",
    "\n",
    "        # Accumulate ground truth source ids\n",
    "        for ground_truth_source in ground_truth_sources:\n",
    "            total_sources.append(ground_truth_source)\n",
    "\n",
    "        # Record scores for true and false infra\n",
    "        for j, struct_id in enumerate(struct_ids):\n",
    "            if struct_id in ground_truth_sources:\n",
    "                association_scores.append(scores[j])\n",
    "            else:\n",
    "                false_association_scores.append(scores[j])\n",
    "\n",
    "        # Record if true source is among top 3 potential sources\n",
    "        source_in_top_3 = False\n",
    "        for j, struct_id in enumerate(struct_ids[0:3]):\n",
    "            if struct_id in ground_truth_sources:\n",
    "                source_in_top_3 = True\n",
    "                break\n",
    "        top_3_source_rate.append(source_in_top_3)\n",
    "\n",
    "    return (\n",
    "        association_scores,\n",
    "        false_association_scores,\n",
    "        top_source_rate,\n",
    "        top_3_source_rate,\n",
    "        total_sources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FB2BObyibfLf"
   },
   "outputs": [],
   "source": [
    "def generate_metrics(\n",
    "    asa_v1, asa_v2, asa_v3, base_algo, gfw_gdf, groundtruth_slicks, unassociated_slicks\n",
    "):\n",
    "    associated_infra_v1 = calculate_associated_infra(\n",
    "        groundtruth_slicks, gfw_gdf, asa_v1\n",
    "    )\n",
    "    associated_infra_v2 = calculate_associated_infra(\n",
    "        groundtruth_slicks, gfw_gdf, asa_v2\n",
    "    )\n",
    "    associated_infra_v3 = calculate_associated_infra(\n",
    "        groundtruth_slicks, gfw_gdf, asa_v3\n",
    "    )\n",
    "    associated_infra_baseline = calculate_associated_infra(\n",
    "        groundtruth_slicks, gfw_gdf, base_algo, True\n",
    "    )\n",
    "\n",
    "    unassociated_infra_v1 = calculate_associated_infra(\n",
    "        unassociated_slicks, gfw_gdf, asa_v1\n",
    "    )\n",
    "    unassociated_infra_v2 = calculate_associated_infra(\n",
    "        unassociated_slicks, gfw_gdf, asa_v2\n",
    "    )\n",
    "    unassociated_infra_v3 = calculate_associated_infra(\n",
    "        unassociated_slicks, gfw_gdf, asa_v3\n",
    "    )\n",
    "    unassociated_infra_baseline = calculate_associated_infra(\n",
    "        unassociated_slicks, gfw_gdf, base_algo, True\n",
    "    )\n",
    "\n",
    "    non_source_max_v1 = highest_false_score(unassociated_infra_v1, groundtruth_slicks)\n",
    "    non_source_max_v2 = highest_false_score(unassociated_infra_v2, groundtruth_slicks)\n",
    "    non_source_max_v3 = highest_false_score(unassociated_infra_v3, groundtruth_slicks)\n",
    "    non_source_max_baseline = highest_false_score(\n",
    "        unassociated_infra_baseline, groundtruth_slicks\n",
    "    )\n",
    "\n",
    "    (\n",
    "        true_association_scores_v1,\n",
    "        false_association_scores_v1,\n",
    "        top_source_rate_v1,\n",
    "        top_3_source_rate_v1,\n",
    "        total_sources_v1,\n",
    "    ) = scores_and_rates(associated_infra_v1, groundtruth_slicks)\n",
    "    (\n",
    "        true_association_scores_v2,\n",
    "        false_association_scores_v2,\n",
    "        top_source_rate_v2,\n",
    "        top_3_source_rate_v2,\n",
    "        total_sources_v2,\n",
    "    ) = scores_and_rates(associated_infra_v2, groundtruth_slicks)\n",
    "    (\n",
    "        true_association_scores_v3,\n",
    "        false_association_scores_v3,\n",
    "        top_source_rate_v3,\n",
    "        top_3_source_rate_v3,\n",
    "        total_sources_v3,\n",
    "    ) = scores_and_rates(associated_infra_v3, groundtruth_slicks)\n",
    "    (\n",
    "        true_association_scores_baseline,\n",
    "        false_association_scores_baseline,\n",
    "        top_source_rate_baseline,\n",
    "        top_3_source_rate_baseline,\n",
    "        total_sources_baseline,\n",
    "    ) = scores_and_rates(associated_infra_baseline, groundtruth_slicks)\n",
    "    true_association_scores = [\n",
    "        sum(true_association_scores_v1) / len(true_association_scores_v1),\n",
    "        sum(true_association_scores_v2) / len(true_association_scores_v2),\n",
    "        sum(true_association_scores_v3) / len(true_association_scores_v3),\n",
    "        sum(true_association_scores_baseline) / len(true_association_scores_baseline),\n",
    "    ]\n",
    "    false_association_scores = [\n",
    "        sum(false_association_scores_v1) / len(false_association_scores_v1),\n",
    "        sum(false_association_scores_v2) / len(false_association_scores_v2),\n",
    "        sum(false_association_scores_v3) / len(false_association_scores_v3),\n",
    "        sum(false_association_scores_baseline) / len(false_association_scores_baseline),\n",
    "    ]\n",
    "\n",
    "    top_source_rate = [\n",
    "        sum(top_source_rate_v1) / len(top_source_rate_v1),\n",
    "        sum(top_source_rate_v2) / len(top_source_rate_v2),\n",
    "        sum(top_source_rate_v3) / len(top_source_rate_v3),\n",
    "        sum(top_source_rate_baseline) / len(top_source_rate_baseline),\n",
    "    ]\n",
    "\n",
    "    top_3_source_rate = [\n",
    "        sum(top_3_source_rate_v1) / len(top_3_source_rate_v1),\n",
    "        sum(top_3_source_rate_v2) / len(top_3_source_rate_v2),\n",
    "        sum(top_3_source_rate_v3) / len(top_3_source_rate_v3),\n",
    "        sum(top_3_source_rate_baseline) / len(top_3_source_rate_baseline),\n",
    "    ]\n",
    "\n",
    "    avg_max_non_source_score = [\n",
    "        sum(non_source_max_v1) / len(non_source_max_v1),\n",
    "        sum(non_source_max_v2) / len(non_source_max_v2),\n",
    "        sum(non_source_max_v3) / len(non_source_max_v1),\n",
    "        sum(non_source_max_baseline) / len(non_source_max_baseline),\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        true_association_scores,\n",
    "        false_association_scores,\n",
    "        top_source_rate,\n",
    "        top_3_source_rate,\n",
    "        avg_max_non_source_score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hQOTgSNgqGl"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ebeva\\SkyTruth\\cv3\\infrastructure_validation_points.csv\")\n",
    "df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads)\n",
    "slick_gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "slick_gdf.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rNnImiECJcd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ebeva\\SkyTruth\\cv3\\nonoise_SAR_Fixed_Infrastructure.csv\")\n",
    "gfw_gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=[Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])],\n",
    "    crs=\"EPSG:4326\",  # Set the coordinate reference system to WGS84\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = r\"C:\\Users\\ebeva\\SkyTruth\\cv3\\s1_scene_envelope\"\n",
    "scene_id_to_gdf = {}\n",
    "for scene_id in np.unique(slick_gdf[\"scene_id\"].values):\n",
    "    s1_scene = get_s1_scene(scene_id, download_path=download_path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePkcJR_t-Sb_",
    "outputId": "f5453e3f-788d-42e3-9e63-17fd9adc76a3"
   },
   "outputs": [],
   "source": [
    "groundtruth_slicks = slick_gdf[slick_gdf[\"structure_ids\"] != \"[]\"]\n",
    "unassociated_slicks = slick_gdf[slick_gdf[\"structure_ids\"] == \"[]\"]\n",
    "print(len(groundtruth_slicks))\n",
    "print(len(unassociated_slicks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMadI5wG0Eqz"
   },
   "source": [
    "Algorithm Versions Referenced in Analysis\n",
    "\n",
    "**Version 1**\n",
    "```\n",
    "C_i = neighbor_weights - decay * dists / radius_of_interest\n",
    "```\n",
    "**Version 2**\n",
    "```\n",
    "C_i = neighbor_weights * (1 - decay * dists / radius_of_interest)\n",
    "```\n",
    "**Version 3**\n",
    "```\n",
    "C_i = neighbor_weights * np.exp(-decay * dists / radius_of_interest)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfw_gdf[\"structure_start_date\"] = pd.to_datetime(gfw_gdf[\"structure_start_date\"])\n",
    "gfw_gdf[\"structure_end_date\"] = pd.to_datetime(gfw_gdf[\"structure_end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "gVgnFXKkG4E_",
    "outputId": "16e28fcf-dcb7-43d5-fc0d-e6941b73c970"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=0.01, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=0.01, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=0.01, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_001,\n",
    "    false_association_scores_001,\n",
    "    top_source_rate_001,\n",
    "    top_3_source_rate_001,\n",
    "    avg_max_score_001,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "show_plots(\n",
    "    true_association_scores_001,\n",
    "    false_association_scores_001,\n",
    "    top_source_rate_001,\n",
    "    top_3_source_rate_001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "HQBIv4S3Uxg9",
    "outputId": "f4614c3b-c564-440f-b662-b2f6b69bb608"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=0.05, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=0.05, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=0.05, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_005,\n",
    "    false_association_scores_005,\n",
    "    top_source_rate_005,\n",
    "    top_3_source_rate_005,\n",
    "    avg_max_score_005,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "show_plots(\n",
    "    true_association_scores_005,\n",
    "    false_association_scores_005,\n",
    "    top_source_rate_005,\n",
    "    top_3_source_rate_005,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "cZM7KB-Mz6u7",
    "outputId": "eb9505a0-eb6a-44ee-f49e-b3dfb7030565"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=0.1, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=0.1, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=0.1, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_01,\n",
    "    false_association_scores_01,\n",
    "    top_source_rate_01,\n",
    "    top_3_source_rate_01,\n",
    "    avg_max_score_01,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_01, false_association_scores_01, top_source_rate_01, top_3_source_rate_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "OGApYauAWr55",
    "outputId": "2942972a-6a35-4a4f-d11b-bef7886de901"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=0.5, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=0.5, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=0.5, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_05,\n",
    "    false_association_scores_05,\n",
    "    top_source_rate_05,\n",
    "    top_3_source_rate_05,\n",
    "    avg_max_score_05,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_05, false_association_scores_05, top_source_rate_05, top_3_source_rate_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "g8jAzkiSYE9M",
    "outputId": "9437e834-8e00-431d-ae7c-711e1b3eabc0"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=1.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=1.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=1.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_1,\n",
    "    false_association_scores_1,\n",
    "    top_source_rate_1,\n",
    "    top_3_source_rate_1,\n",
    "    avg_max_score_1,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_1, false_association_scores_1, top_source_rate_1, top_3_source_rate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "bDarqvucYI5c",
    "outputId": "7172eb51-29f4-4b01-f374-12d51e6c13f3"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=2.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=2.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=2.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_2,\n",
    "    false_association_scores_2,\n",
    "    top_source_rate_2,\n",
    "    top_3_source_rate_2,\n",
    "    avg_max_score_2,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_2, false_association_scores_2, top_source_rate_2, top_3_source_rate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "PDyF0Ri4YQ0x",
    "outputId": "82e3de1f-6cf5-46fa-cdc7-c3191486edb5"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=4.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=4.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=4.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_4,\n",
    "    false_association_scores_4,\n",
    "    top_source_rate_4,\n",
    "    top_3_source_rate_4,\n",
    "    avg_max_score_4,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_4, false_association_scores_4, top_source_rate_4, top_3_source_rate_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Yae9qW1WY0tX",
    "outputId": "ee6aa0d8-99c3-48f0-bdd3-ec8318f8a595"
   },
   "outputs": [],
   "source": [
    "asa_v1 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=1, decay_factor=8.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v2 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=2, decay_factor=8.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "asa_v3 = VersionedInfrastructureAnalyzer(\n",
    "    s1_scene, version=3, decay_factor=8.0, infra_gdf=gfw_gdf\n",
    ")\n",
    "(\n",
    "    true_association_scores_8,\n",
    "    false_association_scores_8,\n",
    "    top_source_rate_8,\n",
    "    top_3_source_rate_8,\n",
    "    avg_max_score_8,\n",
    ") = generate_metrics(\n",
    "    asa_v1,\n",
    "    asa_v2,\n",
    "    asa_v3,\n",
    "    point_to_polygon_probability,\n",
    "    gfw_gdf,\n",
    "    groundtruth_slicks,\n",
    "    unassociated_slicks,\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# show_plots(true_association_scores_8, false_association_scores_8, top_source_rate_8, top_3_source_rate_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX0zoGrih2gf"
   },
   "outputs": [],
   "source": [
    "for v in range(0, 3):\n",
    "    decay_rates = [0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 4.0, 8.0]\n",
    "    true_association_scores_v1 = [\n",
    "        true_association_scores_001[v],\n",
    "        true_association_scores_005[v],\n",
    "        true_association_scores_01[v],\n",
    "        true_association_scores_05[v],\n",
    "        true_association_scores_1[v],\n",
    "        true_association_scores_2[v],\n",
    "        true_association_scores_4[v],\n",
    "        true_association_scores_8[v],\n",
    "    ]\n",
    "\n",
    "    false_association_scores_v1 = [\n",
    "        false_association_scores_001[v],\n",
    "        false_association_scores_005[v],\n",
    "        false_association_scores_01[v],\n",
    "        false_association_scores_05[v],\n",
    "        false_association_scores_1[v],\n",
    "        false_association_scores_2[v],\n",
    "        false_association_scores_4[v],\n",
    "        false_association_scores_8[v],\n",
    "    ]\n",
    "\n",
    "    top_source_rate_v1 = [\n",
    "        top_source_rate_001[v],\n",
    "        top_source_rate_005[v],\n",
    "        top_source_rate_01[v],\n",
    "        top_source_rate_05[v],\n",
    "        top_source_rate_1[v],\n",
    "        top_source_rate_2[v],\n",
    "        top_source_rate_4[v],\n",
    "        top_source_rate_8[v],\n",
    "    ]\n",
    "\n",
    "    top_3_source_rate_v1 = [\n",
    "        top_3_source_rate_001[v],\n",
    "        top_3_source_rate_005[v],\n",
    "        top_3_source_rate_01[v],\n",
    "        top_3_source_rate_05[v],\n",
    "        top_3_source_rate_1[v],\n",
    "        top_3_source_rate_2[v],\n",
    "        top_3_source_rate_4[v],\n",
    "        top_3_source_rate_8[v],\n",
    "    ]\n",
    "    avg_max_non_source_score = [\n",
    "        avg_max_score_001[v],\n",
    "        avg_max_score_005[v],\n",
    "        avg_max_score_01[v],\n",
    "        avg_max_score_05[v],\n",
    "        avg_max_score_1[v],\n",
    "        avg_max_score_2[v],\n",
    "        avg_max_score_4[v],\n",
    "        avg_max_score_8[v],\n",
    "    ]\n",
    "    plot_metrics_by_decay(\n",
    "        decay_rates,\n",
    "        true_association_scores_v1,\n",
    "        false_association_scores_v1,\n",
    "        top_source_rate_v1,\n",
    "        top_3_source_rate_v1,\n",
    "        avg_max_non_source_score,\n",
    "        version=v + 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
