{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vess_infra_true_ranks(df, coll_column = 'collated_score'):\n",
    "    vessel_true_rank = []\n",
    "    infra_true_rank = []\n",
    "    for slick_id, group in df.groupby('slick'):\n",
    "        group.sort_values(by=coll_column, ascending=False, inplace=True)\n",
    "        group['calculated_rank'] = list(range(1,len(group)+1))\n",
    "        true_source = group[group['hitl_verification']==True]\n",
    "        if len(true_source)!=1:\n",
    "            continue\n",
    "            # raise BaseException(\"can't have more than one true source per slick\")\n",
    "\n",
    "        calc_rank = true_source['calculated_rank'].values[0]\n",
    "        if true_source['type'].values[0]==1:\n",
    "            vessel_true_rank.append(calc_rank)\n",
    "        else:\n",
    "            infra_true_rank.append(calc_rank)\n",
    "    return vessel_true_rank, infra_true_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = r'C:\\Users\\ebeva\\SkyTruth\\cv3\\slick_to_source dump 2024-12-20.csv'\n",
    "# df = pd.read_csv(csv_path)\n",
    "# df = df.drop(columns=['create_time',\n",
    "#         'hitl_user', 'hitl_time', 'active', 'git_hash', 'id-2', 'name',\n",
    "#        'email', 'emailVerified', 'image', 'role', 'id-3'])\n",
    "# df['calculated_rank'] = 0\n",
    "# df['custom_rank'] = 0\n",
    "# df['calc_coll_score'] = 0\n",
    "# df['custom_coll_score'] = 0\n",
    "# df = df[df['hitl_notes'] != 'multisource']\n",
    "# df = df[df['hitl_notes'] != 'Multisource']\n",
    "# df = df[df['hitl_notes'] != 'infrastructure']\n",
    "\n",
    "\n",
    "# not_noise = []\n",
    "# for source in df.iloc:\n",
    "#     if source['coincidence_score'] == source['collated_score']:\n",
    "#         not_noise.append(False)\n",
    "#     else:\n",
    "#         not_noise.append(True)\n",
    "# df = df[not_noise]\n",
    "\n",
    "csv_path = r'C:\\Users\\ebeva\\SkyTruth\\cv3\\slick_to_source dump 2024-12-31.csv'\n",
    "true_slick_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_df = pd.read_csv(r'C:\\Users\\ebeva\\SkyTruth\\cv3\\asa_analysis\\reattempt_rerun_with_weighted_8hour.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataframe that combines infra sources with new vessel sources (increased time track + weighted curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'source', 'type', 'hitl_verification','slick', 'coincidence_score', 'collated_score', 'custom_coin_score', 'custom_coll_score', 'calculated_rank'\n",
    "]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "temp_w = 2.0\n",
    "over_w = 1.0\n",
    "dist_w = 2.0\n",
    "\n",
    "for slick_id,group in true_slick_df.groupby('slick'):\n",
    "    true_source = group[group['hitl_verification'] == True]\n",
    "    if len(true_source)==0:\n",
    "        continue\n",
    "    true_type = true_source['type'].values[0]\n",
    "    # if true_type==1:\n",
    "    #     print(true_source['st_name'])\n",
    "    new_vess_sources = rerun_df[rerun_df['slick_id']==slick_id]\n",
    "    new_vess_sources['coincidence_score'] = (over_w*new_vess_sources['overlap_score'] + temp_w*new_vess_sources['temporal_score'] + dist_w*new_vess_sources['distance_score'])/(over_w + temp_w + dist_w)\n",
    "    new_vess_sources = new_vess_sources.sort_values(by='coincidence_score', ascending=False)\n",
    "    for i,vess in new_vess_sources.iterrows(): \n",
    "        row = {'source':vess['st_name'],\n",
    "                'type':1,\n",
    "                'hitl_verification': vess['st_name']==true_source['st_name'].values[0],\n",
    "                'slick': slick_id,\n",
    "                'coincidence_score':vess['coincidence_score'],\n",
    "                'collated_score':vess['coll_score'],\n",
    "                'custom_coin_score':0, 'custom_coll_score':0, 'calculated_rank':0\n",
    "            }\n",
    "        \n",
    "        new_row = pd.DataFrame([row])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "    for i,infra in group[group['type']==2].iterrows():\n",
    "        row = {'source':infra['st_name'],\n",
    "            'type':2,\n",
    "            'hitl_verification': infra['hitl_verification'],\n",
    "            'slick': slick_id,\n",
    "            'coincidence_score':infra['coincidence_score'],\n",
    "            'collated_score':infra['collated_score'],\n",
    "            'custom_coin_score':0, 'custom_coll_score':0, 'calculated_rank':0\n",
    "        }\n",
    "        new_row = pd.DataFrame([row])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "        # new_true_vess = rerun_df[rerun_df['st_name']==true_source['st_name'].values[0]][rerun_df['slick_id']==slick_id]\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFRA_MEAN = 0.58\n",
    "INFRA_STD = 0.19\n",
    "VESSEL_MEAN = 0.64\n",
    "VESSEL_STD = 0.122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = df[df['type']==2][df['hitl_verification']==True]#['coincidence_score'].values\n",
    "vess_list = df[df['type']==1][df['hitl_verification']==True]#['coincidence_score'].values\n",
    "INFRA_COIN = infra_list['coincidence_score'].values\n",
    "VESS_COIN = vess_list['coincidence_score'].values\n",
    "NEW_INFRA_MEAN, NEW_INFRA_STD = np.mean(INFRA_COIN), np.std(INFRA_COIN)\n",
    "NEW_VESSEL_MEAN, NEW_VESSEL_STD = np.mean(VESS_COIN), np.std(VESS_COIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFRA MEAN:\", INFRA_MEAN, \"--->\", NEW_INFRA_MEAN)\n",
    "print(\"INFRA STD:\", INFRA_STD, \"--->\", NEW_INFRA_STD)\n",
    "print(\"VESSEL_MEAN:\", VESSEL_MEAN, \"--->\", NEW_VESSEL_MEAN)\n",
    "print(\"VESSEL_STD:\", VESSEL_STD, \"--->\", NEW_VESSEL_STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Analyze only slicks with multiple source types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed_source_examples = []\n",
    "# non_mixed_source = []\n",
    "# for slick,group in df.groupby('slick'):\n",
    "#     # print(np.unique(group['type'].values))\n",
    "#     unique_source_types = np.unique(group['type'].values)\n",
    "#     if len(unique_source_types)==2:\n",
    "#         mixed_source_examples.append(slick)\n",
    "#     else:\n",
    "#         non_mixed_source.append(unique_source_types[0])\n",
    "# df = df[df[\"slick\"].isin(mixed_source_examples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate collation score with fixed vessel mean/std and variable infra mean/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"Calculate collated score by adjusting infra distributions\")\n",
    "\n",
    "infra_mean_adjustments = list(np.arange(0, .9, 0.025))\n",
    "infra_std_adjustments = list(np.arange(0.0, 0.5, 0.01))\n",
    "\n",
    "infra_ranking_dps = [] \n",
    "vess_ranking_dps = []\n",
    "vess_top_3_dps = []\n",
    "infra_top_3_dps = []\n",
    "\n",
    "# Wrap outer loop with tqdm for progress bar\n",
    "for infra_mean_adjust in tqdm(infra_mean_adjustments, desc=\"Adjusting Infra Mean\"):\n",
    "    for infra_std_adjust in tqdm(infra_std_adjustments, desc=\"Adjusting Infra Std\", leave=False):\n",
    "        custom_coll_scores = []\n",
    "        for source in df.iloc:\n",
    "            m, s = (NEW_VESSEL_MEAN, NEW_VESSEL_STD) if source['type'] == 1 else (infra_mean_adjust, infra_std_adjust)\n",
    "            custom_coll_scores.append((source['coincidence_score'] - m) / s)\n",
    "        df['custom_coll_score'] = custom_coll_scores\n",
    "\n",
    "        infra_list = df[df['type'] == 2][df['hitl_verification'] == True]  # Filtered infra list\n",
    "        vess_list = df[df['type'] == 1][df['hitl_verification'] == True]  # Filtered vessel list\n",
    "        vessel_true_rank, infra_true_rank = vess_infra_true_ranks(df, coll_column='custom_coll_score')\n",
    "\n",
    "        # Append ranking data points\n",
    "        infra_ranking_dps.append((infra_mean_adjust, infra_std_adjust, np.mean(infra_true_rank)))\n",
    "        vess_ranking_dps.append((infra_mean_adjust, infra_std_adjust, np.mean(vessel_true_rank)))\n",
    "\n",
    "        vess_top_3_dps.append((infra_mean_adjust, infra_std_adjust, np.sum(np.array(vessel_true_rank)<=3) / len(vessel_true_rank)))\n",
    "        infra_top_3_dps.append((infra_mean_adjust, infra_std_adjust, np.sum(np.array(infra_true_rank)<=3) / len(infra_true_rank)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = df[df['type']==2][df['hitl_verification']==True]#['coincidence_score'].values\n",
    "vess_list = df[df['type']==1][df['hitl_verification']==True]#['coincidence_score'].\n",
    "\n",
    "print(\"vess mean and std:\",round(np.mean(vess_list['custom_coll_score']),3), round(np.std(vess_list['custom_coll_score']),3))\n",
    "print(\"infra mean and std\",round(np.mean(infra_list['custom_coll_score']),3), round(np.std(infra_list['custom_coll_score']),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_ranking_dps = []\n",
    "for i in range(len(infra_ranking_dps)):\n",
    "    x = infra_ranking_dps[i][0]\n",
    "    y = infra_ranking_dps[i][1]\n",
    "    max_ranking_dps.append([x,y,max(infra_ranking_dps[i][2], vess_ranking_dps[i][2])])\n",
    "\n",
    "minimum = 5\n",
    "for i in range(len(max_ranking_dps)):\n",
    "    rank = max_ranking_dps[i][2]\n",
    "    # print(rank)\n",
    "    if rank < minimum:\n",
    "        minimum = rank\n",
    "        mean = max_ranking_dps[i][0]\n",
    "        std = max_ranking_dps[i][1]\n",
    "        min_vess_ranking = vess_ranking_dps[i][2]\n",
    "        min_infra_ranking = infra_ranking_dps[i][2]\n",
    "\n",
    "print(\"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\", round(mean,3),\"MEAN AND\", round(std,3), \"STD\")\n",
    "print(\"With vess avg ranking:\", min_vess_ranking)\n",
    "print(\"With infra avg ranking:\", min_infra_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAL MEAN AND STD ADJUSTMENT FOUND AT 0.3 MEAN AND 0.22 STD\n",
    "# With vess avg ranking: 1.3655913978494623\n",
    "# With infra avg ranking: 1.3650793650793651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set of points\n",
    "x1, y1, z1 = np.array(infra_ranking_dps).transpose(1,0)\n",
    "\n",
    "# Second set of points\n",
    "x2, y2, z2 = np.array(vess_ranking_dps).transpose(1,0)\n",
    "\n",
    "# Create the figure and add traces\n",
    "fig = go.Figure()\n",
    "\n",
    "# Infra Avg Ranking\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x1, y=y1, z=z1,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=z1,  # Use z-values for color\n",
    "        colorscale='Blues',  # Gradient scale\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Infra Avg Ranking'\n",
    "))\n",
    "\n",
    "# Vessel Avg Ranking\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x2, y=y2, z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=z2,  # Use z-values for color\n",
    "        colorscale='Reds',\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Vessel Avg Ranking'\n",
    "))\n",
    "\n",
    "# Optimized Point\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[mean], y=[std], z=[minimum],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='green',\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Optimized Point'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Mean Adjustment',\n",
    "        yaxis_title='Std Adjustment',\n",
    "        zaxis_title='Avg Ranking',\n",
    "        aspectratio=dict(x=1, y=1, z=1.0)\n",
    "    ),\n",
    "    title='Z (avg ranking) at various X (mean adjustment) and Y (std adjustmentment)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_top_3_dps = []\n",
    "for i in range(len(infra_top_3_dps)):\n",
    "    x = infra_top_3_dps[i][0]\n",
    "    y = infra_top_3_dps[i][1]\n",
    "    min_top_3_dps.append([x,y,min(infra_top_3_dps[i][2], vess_top_3_dps[i][2])])\n",
    "\n",
    "maximum = 0\n",
    "for i in range(len(min_top_3_dps)):\n",
    "    bot = min_top_3_dps[i][2]\n",
    "    # print(rank)\n",
    "    if bot > maximum:\n",
    "        maximum = bot\n",
    "        mean = min_top_3_dps[i][0]\n",
    "        std = min_top_3_dps[i][1]\n",
    "        min_vess_top_3 = vess_top_3_dps[i][2]\n",
    "        min_infra_top_3 = infra_top_3_dps[i][2]\n",
    "\n",
    "print(\"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\", round(mean,3),\"MEAN AND\", round(std,3), \"STD\")\n",
    "print(\"With vess top 3 rate:\", min_vess_top_3)\n",
    "print(\"With infra top 3 rate:\", min_infra_top_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAL MEAN AND STD ADJUSTMENT FOUND AT 0.35 MEAN AND 0.26 STD\n",
    "# With vess top 3 rate: 0.967741935483871\n",
    "# With infra top 3 rate: 0.9682539682539683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set of points\n",
    "x1, y1, z1 = np.array(infra_top_3_dps).transpose(1,0)\n",
    "\n",
    "# Second set of points\n",
    "x2, y2, z2 = np.array(vess_top_3_dps).transpose(1,0)\n",
    "\n",
    "# Create the figure and add traces\n",
    "fig = go.Figure()\n",
    "\n",
    "# Infra Avg Ranking\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x1, y=y1, z=z1,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=z1,  # Use z-values for color\n",
    "        colorscale='Blues',  # Gradient scale\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Infra Top 3 Rate'\n",
    "))\n",
    "\n",
    "# Vessel Avg Ranking\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x2, y=y2, z=z2,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=z2,  # Use z-values for color\n",
    "        colorscale='Reds',\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Vessel Top 3 Rate'\n",
    "))\n",
    "\n",
    "# Optimized Point\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[mean], y=[std], z=[maximum],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='green',\n",
    "        opacity=1.0\n",
    "    ),\n",
    "    name='Optimized Point'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Mean Adjustment',\n",
    "        yaxis_title='Std Adjustment',\n",
    "        zaxis_title='Top 3 Rate',\n",
    "        aspectratio=dict(x=1, y=1, z=1.0)\n",
    "    ),\n",
    "    title='Z (top 3 rate) at various X (mean adjustment) and Y (std adjustmentment)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate absolute ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "sort_by = 'coincidence_score'\n",
    "ranks_old = []\n",
    "# sort_by = 'coll_score'\n",
    "# sort_by = 'collated_score'\n",
    "for slick,g in df.groupby('slick'):\n",
    "    g_old = true_slick_df[true_slick_df['slick'] == slick]\n",
    "    # if slick != 3573115:\n",
    "    #     continue\n",
    "    true_source = g[g['hitl_verification'] == True]\n",
    "    true_source_old = g_old[g_old['hitl_verification'] == True]\n",
    "    if len(true_source)==0:\n",
    "        continue\n",
    "    if true_source['type'].values[0]==1:\n",
    "        g = g[g['type']==true_source['type'].values[0]]\n",
    "        g = g.sort_values(by=sort_by, ascending=False)\n",
    "\n",
    "        g_old = g_old[g_old['type']==true_source_old['type'].values[0]]\n",
    "        g_old = g_old.sort_values(by=sort_by, ascending=False)\n",
    "\n",
    "        g['calculated_rank'] = list(range(1,len(g)+1))\n",
    "        g_old['calculated_rank'] = list(range(1,len(g_old)+1))\n",
    "\n",
    "        # if g[g['hitl_verification'] == True]['calculated_rank'].values[0] > 3:\n",
    "        #         print(slick)\n",
    "        g_rank = g[g['hitl_verification'] == True]['calculated_rank'].values[0]\n",
    "        g_rank_old = g_old[g_old['hitl_verification'] == True]['calculated_rank'].values[0]\n",
    "        ranks.append(g_rank)\n",
    "        ranks_old.append(g_rank_old)\n",
    "\n",
    "        if g_rank > g_rank_old:\n",
    "             print(slick)\n",
    "             print(g_rank_old, \"--->\", g_rank)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ranks_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate temporal weighting adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'source', \n",
    "    'type', \n",
    "    'hitl_verification',\n",
    "    'slick', \n",
    "    'coincidence_score', \n",
    "    'collated_score', \n",
    "    'custom_coin_score', \n",
    "    'custom_coll_score', \n",
    "    'calculated_rank'\n",
    "    'overlap_score',\n",
    "    'temporal_score',\n",
    "    'distance_score'\n",
    "]\n",
    "df_temps = pd.DataFrame(columns=columns)\n",
    "for slick_id,group in true_slick_df.groupby('slick'):\n",
    "    true_source = group[group['hitl_verification'] == True]\n",
    "    if len(true_source)==0:\n",
    "        continue\n",
    "    true_type = true_source['type'].values[0]\n",
    "    # if true_type==1:\n",
    "    #     print(true_source['st_name'])\n",
    "    new_vess_sources = rerun_df[rerun_df['slick_id']==slick_id]\n",
    "    new_vess_sources = new_vess_sources.sort_values(by='coincidence_score', ascending=False)\n",
    "    for i,vess in new_vess_sources.iterrows(): \n",
    "        row = {'source':vess['st_name'],\n",
    "                'type':1,\n",
    "                'hitl_verification': vess['st_name']==true_source['st_name'].values[0],\n",
    "                'slick': slick_id,\n",
    "                'coincidence_score':vess['coincidence_score'],\n",
    "                'collated_score':vess['coll_score'],\n",
    "                'overlap_score': vess['overlap_score'],\n",
    "                'temporal_score':vess['temporal_score'],\n",
    "                'distance_score':vess['distance_score'],\n",
    "                'custom_coin_score':0, 'custom_coll_score':0, 'calculated_rank':0\n",
    "            }\n",
    "        \n",
    "        new_row = pd.DataFrame([row])\n",
    "        df_temps = pd.concat([df_temps, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_temps = list(np.arange(0.0, 10, 0.25))\n",
    "vess_ranking_dps = []\n",
    "vess_top_3_dps = []\n",
    "for w_temp in w_temps:\n",
    "    custom_coll_scores = []\n",
    "    for source in df_temps.iloc:\n",
    "        custom_coll_scores.append((2*source['distance_score'] + 1*source['overlap_score'] + w_temp*source['temporal_score'])/(3 + w_temp))\n",
    "    df_temps['custom_coll_score'] = custom_coll_scores\n",
    "\n",
    "    # infra_list = df_temps[df_temps['type'] == 2][df_temps['hitl_verification'] == True]  # Filtered infra list\n",
    "    vess_list = df_temps[df_temps['type'] == 1][df_temps['hitl_verification'] == True]  # Filtered vessel list\n",
    "    vessel_true_rank, infra_true_rank = vess_infra_true_ranks(df_temps, coll_column='custom_coll_score')\n",
    "\n",
    "    # Append ranking data points\n",
    "    # infra_ranking_dps.append((infra_mean_adjust, infra_std_adjust, np.mean(infra_true_rank)))\n",
    "    vess_ranking_dps.append(np.mean(vessel_true_rank))\n",
    "\n",
    "    vess_top_3_dps.append(np.sum(np.array(vessel_true_rank)<=3) / len(vessel_true_rank))\n",
    "    # infra_top_3_dps.append((infra_mean_adjust, infra_std_adjust, np.sum(np.array(infra_true_rank)<=3) / len(infra_true_rank)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data (replace these with your actual data)\n",
    "# w_temps = [...]\n",
    "# vess_ranking_dps = [...]\n",
    "# vess_top_3_dps = [...]\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n",
    "\n",
    "# First plot: Average vessel rank\n",
    "axes[0].plot(w_temps, vess_ranking_dps, label='Average Vessel Rank', color='blue')\n",
    "axes[0].set_title(\"Average Vessel Rank\")\n",
    "axes[0].set_xlabel(\"Temporal Weighting Adjustment\")\n",
    "axes[0].set_ylabel(\"Average Rank\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Second plot: Top 3 source rate\n",
    "axes[1].plot(w_temps, vess_top_3_dps, label='Top 3 Source Rate', color='green')\n",
    "axes[1].set_title(\"Top 3 Source Rate\")\n",
    "axes[1].set_xlabel(\"Temporal Weighting Adjustment\")\n",
    "axes[1].set_ylabel(\"Source Rate\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Add an overall title\n",
    "fig.suptitle(\"Comparison of Vessel Ranking Metrics with 8 Hour AIS track\", fontsize=16)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust rect to make space for the title\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
