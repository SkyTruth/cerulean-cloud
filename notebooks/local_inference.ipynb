{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import AsyncMock, Mock, patch\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Make sure your dotenv file has the following defined:\n",
    "load_dotenv()\n",
    "GIT_FOLDER = os.environ['GIT_FOLDER']\n",
    "TITILER_URL = os.environ['TITILER_URL']\n",
    "TITILER_API_KEY = os.environ['TITILER_API_KEY']\n",
    "API_KEY = os.environ['API_KEY']\n",
    "MODEL_PATH_LOCAL = os.environ['MODEL_PATH_LOCAL']\n",
    "\n",
    "if not (GIT_FOLDER and TITILER_URL and TITILER_API_KEY and MODEL_PATH_LOCAL):\n",
    "    print(\"ERRROR: Failed to find all the necessary environment variables!!!\")\n",
    "    # Note, you must restart the kernel if you want to load new environment variables\n",
    "\n",
    "if GIT_FOLDER not in sys.path:\n",
    "    sys.path.append(GIT_FOLDER)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerulean_cloud.models import get_model\n",
    "from cerulean_cloud.tiling import TMS, offset_bounds_from_base_tiles\n",
    "from cerulean_cloud.titiler_client import TitilerClient\n",
    "from cerulean_cloud.cloud_run_orchestrator.clients import img_array_to_b64_image\n",
    "from cerulean_cloud.cloud_run_orchestrator.schema import OrchestratorInput\n",
    "from cerulean_cloud.cloud_run_orchestrator.handler import _orchestrate, get_tiler, get_titiler_client, get_roda_sentinelhub_client, get_database_engine\n",
    "from cerulean_cloud.cloud_run_offset_tiles.schema import InferenceInput, PredictPayload\n",
    "from cerulean_cloud.cloud_run_offset_tiles.handler import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastaiunet = {\n",
    "    \"type\": \"FASTAIUNET\",\n",
    "    \"file_path\": \"\",#\"experiments/2024_03_06_18_14_31_7cls_rn101_pr256_z9_fastai_baseline_noamb/tracing_cpu_model.pt\",\n",
    "    \"layers\": [\"VV\"],\n",
    "    \"cls_map\": {\n",
    "        0: \"BACKGROUND\",\n",
    "        1: \"INFRA\",\n",
    "        2: \"NATURAL\",\n",
    "        3: \"COIN_VESSEL\",\n",
    "        4: \"REC_VESSEL\",\n",
    "        5: \"OLD_VESSEL\",\n",
    "        6: \"BACKGROUND\"  # HITL AMBIGUOUS, should never be output by inference_idx\n",
    "    },  # inference_idx maps to class table\n",
    "    \"name\": \"ResNet101 Baseline Noamb\",\n",
    "    \"tile_width_m\": 40844,  # Used to calculate zoom\n",
    "    \"tile_width_px\": 256,  # Used to calculate scale\n",
    "    \"epochs\": 80,\n",
    "    \"thresholds\": {\n",
    "        \"poly_nms_thresh\": 0.4,\n",
    "        \"pixel_nms_thresh\": 0.4,\n",
    "        \"bbox_score_thresh\": 0.1,\n",
    "        \"poly_score_thresh\": 0.01, # JONA Is this working correctly???\n",
    "        \"pixel_score_thresh\": 0.35,\n",
    "        \"groundtruth_dice_thresh\": 0.0\n",
    "    },\n",
    "    \"backbone_size\": 101,\n",
    "    \"zoom_level\":9,\n",
    "    \"scale\":2,\n",
    "    # \"pixel_f1\": 0.0,  # TODO CALCULATE\n",
    "    # \"instance_f1\": 0.0  # TODO CALCULATE\n",
    "}\n",
    "\n",
    "maskrcnn = {\n",
    "    \"type\": \"MASKRCNN\",\n",
    "    \"file_path\": \"\",#\"experiments/2023_10_05_02_22_46_4cls_rnxt101_pr512_px1024_680min_maskrcnn_wd01/scripting_cpu_model.pt\",\n",
    "    \"layers\": ['VV', 'INFRA', 'VESSEL'],\n",
    "    \"cls_map\": {'0': 'BACKGROUND', '1': 'INFRA', '2': 'NATURAL', '3': 'VESSEL'},  # inference_idx maps to class table\n",
    "    \"name\": \"ResNext 101 hires56\",\n",
    "    \"tile_width_m\": 40844,  # Used to calculate zoom\n",
    "    \"tile_width_px\": 512,  # Used to calculate scale\n",
    "    \"epochs\": 122,\n",
    "    \"thresholds\": {\n",
    "        \"poly_nms_thresh\": 0.5,\n",
    "        'pixel_nms_thresh': 0.4,\n",
    "        'bbox_score_thresh': 0.5,\n",
    "        'poly_score_thresh': 0.1,\n",
    "        'pixel_score_thresh': 0.5,\n",
    "        'groundtruth_dice_thresh': 0.0},\n",
    "    \"backbone_size\": 101,\n",
    "    \"zoom_level\":9,\n",
    "    \"scale\":2,\n",
    "    # \"pixel_f1\": 0.461,  # TODO CALCULATE\n",
    "    # \"instance_f1\": 0.47  # TODO CALCULATE\n",
    "}\n",
    "\n",
    "\n",
    "model_dict_predefined=maskrcnn if \"maskrcnn\" in MODEL_PATH_LOCAL else fastaiunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_titiler_client_and_offset_tiles(sentinel_scene, offset=.33):\n",
    "    payload = OrchestratorInput(**sentinel_scene)\n",
    "    TitilerClient_url = os.getenv('TITILER_URL')\n",
    "    titiler_client = TitilerClient(url=TitilerClient_url)\n",
    "    scene_bounds = await titiler_client.get_bounds(payload.sceneid)\n",
    "    tiler = TMS\n",
    "    base_tiles = list(tiler.tiles(*scene_bounds, [payload.zoom], truncate=False))\n",
    "    offset_tile_bounds = offset_bounds_from_base_tiles(base_tiles, offset_amount=offset)\n",
    "    return titiler_client, offset_tile_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = \"S1A_IW_GRDH_1SDV_20240204T184243_20240204T184308_052413_0656A2_1B88\"\n",
    "test_scene = {\"sceneid\": scene_id , \"zoom\":9, \"scale\":2}\n",
    "\n",
    "titler_client , tile_bounds =  await get_titiler_client_and_offset_tiles(test_scene,offset=.66)\n",
    "\n",
    "example_tile_a1 = tile_bounds[37] # 37 and 45\n",
    "example_tile_a2 = tile_bounds[45] # 37 and 45\n",
    "\n",
    "vv_a1 = (await titler_client.get_offset_tile(scene_id, *example_tile_a1,height=512,width=512)).transpose(2,0,1)[0]\n",
    "vv_a2 = (await titler_client.get_offset_tile(scene_id, *example_tile_a2,height=512,width=512)).transpose(2,0,1)[0]\n",
    "\n",
    "plt.imshow(vv_a1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titler_client , tile_bounds =  await get_titiler_client_and_offset_tiles(test_scene,offset=.0)\n",
    "example_tile_b1 = tile_bounds[44] # 44 and 52\n",
    "example_tile_b2 = tile_bounds[52] # 44 and 52\n",
    "\n",
    "vv_b1 = (await titler_client.get_offset_tile(scene_id, *example_tile_b1,height=512,width=512)).transpose(2,0,1)[0]\n",
    "vv_b2 = (await titler_client.get_offset_tile(scene_id, *example_tile_b2,height=512,width=512)).transpose(2,0,1)[0]\n",
    "\n",
    "plt.imshow(vv_b1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titler_client , tile_bounds =  await get_titiler_client_and_offset_tiles(test_scene,offset=.33)\n",
    "example_tile_c1 = tile_bounds[37] # 37 and 45\n",
    "example_tile_c2 = tile_bounds[45] # 37 and 45\n",
    "\n",
    "vv_c1 = (await titler_client.get_offset_tile(scene_id, *example_tile_c1,height=512,width=512)).transpose(2,0,1)[0]\n",
    "vv_c2 = (await titler_client.get_offset_tile(scene_id, *example_tile_c2,height=512,width=512)).transpose(2,0,1)[0]\n",
    "\n",
    "plt.imshow(vv_c1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_dict_predefined,model_path_local=MODEL_PATH_LOCAL)\n",
    "\n",
    "inf_stack_a = [\n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_a1]*len(model_dict_predefined[\"layers\"])))), \n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_a2]*len(model_dict_predefined[\"layers\"])))),\n",
    "    ]\n",
    "bounds_stack_a = [example_tile_a1, example_tile_a2][:len(inf_stack_a)]\n",
    "\n",
    "inf_stack_b = [\n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_b1]*len(model_dict_predefined[\"layers\"])))), \n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_b2]*len(model_dict_predefined[\"layers\"])))),\n",
    "    ]\n",
    "bounds_stack_b = [example_tile_b1, example_tile_b2][:len(inf_stack_b)]\n",
    "\n",
    "inf_stack_c = [\n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_c1]*len(model_dict_predefined[\"layers\"])))), \n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_c2]*len(model_dict_predefined[\"layers\"])))),\n",
    "    ]\n",
    "bounds_stack_c = [example_tile_c1, example_tile_c2][:len(inf_stack_c)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_a = model.predict(inf_stack_a)\n",
    "out_b = model.predict(inf_stack_b)\n",
    "out_c = model.predict(inf_stack_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(model.deserialize(out.stack[0].json_data)['masks'][0].detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_dict_predefined,model_path_local=MODEL_PATH_LOCAL)\n",
    "\n",
    "fc_a = model.postprocess_tileset([out_a],bounds_stack_a)\n",
    "fc_b = model.postprocess_tileset([out_b],bounds_stack_b)\n",
    "fc_c = model.postprocess_tileset([out_c],bounds_stack_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf_a = gpd.GeoDataFrame.from_features(fc_a[\"features\"])\n",
    "gdf_a.plot()\n",
    "print(gdf_a)\n",
    "print(\"________________________________________________________________\")\n",
    "gdf_b = gpd.GeoDataFrame.from_features(fc_b[\"features\"])\n",
    "gdf_b.plot()\n",
    "print(gdf_b)\n",
    "print(\"________________________________________________________________\")\n",
    "gdf_c = gpd.GeoDataFrame.from_features(fc_c[\"features\"])\n",
    "gdf_c.plot()\n",
    "print(gdf_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_f = model.nms_feature_reduction(\n",
    "    features=[fc_a, fc_b, fc_c], min_overlaps_to_keep=0\n",
    ")\n",
    "gdf_f = gpd.GeoDataFrame.from_features(fc_f[\"features\"])\n",
    "gdf_f.plot()\n",
    "gdf_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
