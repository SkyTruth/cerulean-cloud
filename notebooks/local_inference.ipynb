{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import AsyncMock, Mock, patch\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Make sure your dotenv file has the following defined:\n",
    "load_dotenv()\n",
    "GIT_FOLDER = os.environ['GIT_FOLDER']\n",
    "TITILER_URL = os.environ['TITILER_URL']\n",
    "TITILER_API_KEY = os.environ['TITILER_API_KEY']\n",
    "API_KEY = os.environ['API_KEY']\n",
    "MODEL_PATH_LOCAL = os.environ['MODEL_PATH_LOCAL']\n",
    "\n",
    "if not (GIT_FOLDER and TITILER_URL and TITILER_API_KEY and MODEL_PATH_LOCAL):\n",
    "    print(\"ERRROR: Failed to find all the necessary environment variables!!!\")\n",
    "    # Note, you must restart the kernel if you want to load new environment variables\n",
    "\n",
    "if GIT_FOLDER not in sys.path:\n",
    "    sys.path.append(GIT_FOLDER)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerulean_cloud.models import get_model\n",
    "from cerulean_cloud.tiling import TMS, offset_bounds_from_base_tiles\n",
    "from cerulean_cloud.titiler_client import TitilerClient\n",
    "from cerulean_cloud.cloud_run_orchestrator.clients import img_array_to_b64_image\n",
    "from cerulean_cloud.cloud_run_orchestrator.schema import OrchestratorInput\n",
    "from cerulean_cloud.cloud_run_orchestrator.handler import _orchestrate, get_tiler, get_titiler_client, get_roda_sentinelhub_client, get_database_engine\n",
    "from cerulean_cloud.cloud_run_offset_tiles.schema import InferenceInput, PredictPayload\n",
    "from cerulean_cloud.cloud_run_offset_tiles.handler import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastaiunet = {\n",
    "    \"type\": \"FASTAIUNET\",\n",
    "    \"file_path\": \"\",#\"experiments/2024_03_06_18_14_31_7cls_rn101_pr256_z9_fastai_baseline_noamb/tracing_cpu_model.pt\",\n",
    "    \"layers\": [\"VV\"],\n",
    "    \"cls_map\": {\n",
    "        0: \"BACKGROUND\",\n",
    "        1: \"INFRA\",\n",
    "        2: \"NATURAL\",\n",
    "        3: \"COIN_VESSEL\",\n",
    "        4: \"REC_VESSEL\",\n",
    "        5: \"OLD_VESSEL\",\n",
    "        6: \"BACKGROUND\"  # HITL AMBIGUOUS, should never be output by inference_idx\n",
    "    },  # inference_idx maps to class table\n",
    "    \"name\": \"ResNet101 Baseline Noamb\",\n",
    "    \"tile_width_m\": 40844,  # Used to calculate zoom\n",
    "    \"tile_width_px\": 256,  # Used to calculate scale\n",
    "    \"epochs\": 80,\n",
    "    \"thresholds\": {\n",
    "        \"pixel_nms_thresh\": 0.4,\n",
    "        \"bbox_score_thresh\": 0.1,\n",
    "        \"poly_score_thresh\": 0.01, # JONA Is this working correctly???\n",
    "        \"pixel_score_thresh\": 0.35,\n",
    "        \"groundtruth_dice_thresh\": 0.0\n",
    "    },\n",
    "    \"backbone_size\": 101,\n",
    "    \"zoom_level\":9,\n",
    "    \"scale\":2,\n",
    "    # \"pixel_f1\": 0.0,  # TODO CALCULATE\n",
    "    # \"instance_f1\": 0.0  # TODO CALCULATE\n",
    "}\n",
    "\n",
    "maskrcnn = {\n",
    "    \"type\": \"MASKRCNN\",\n",
    "    \"file_path\": \"\",#\"experiments/2023_10_05_02_22_46_4cls_rnxt101_pr512_px1024_680min_maskrcnn_wd01/scripting_cpu_model.pt\",\n",
    "    \"layers\": ['VV', 'INFRA', 'VESSEL'],\n",
    "    \"cls_map\": {'0': 'BACKGROUND', '1': 'INFRA', '2': 'NATURAL', '3': 'VESSEL'},  # inference_idx maps to class table\n",
    "    \"name\": \"ResNext 101 hires56\",\n",
    "    \"tile_width_m\": 40844,  # Used to calculate zoom\n",
    "    \"tile_width_px\": 512,  # Used to calculate scale\n",
    "    \"epochs\": 122,\n",
    "    \"thresholds\": {\n",
    "        'pixel_nms_thresh': 0.4, \n",
    "        'bbox_score_thresh': 0.2, \n",
    "        'poly_score_thresh': 0.2,\n",
    "        'pixel_score_thresh': 0.2, \n",
    "        'groundtruth_dice_thresh': 0.0},\n",
    "    \"backbone_size\": 101,\n",
    "    \"zoom_level\":9,\n",
    "    \"scale\":2,\n",
    "    # \"pixel_f1\": 0.461,  # TODO CALCULATE\n",
    "    # \"instance_f1\": 0.47  # TODO CALCULATE\n",
    "}\n",
    "\n",
    "\n",
    "model_dict_predefined=fastaiunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sceneid = \"S1A_IW_GRDH_1SDV_20240204T184243_20240204T184308_052413_0656A2_1B88\"\n",
    "# payload = OrchestratorInput(sceneid=sceneid)\n",
    "\n",
    "# async def mock_post(_, url: str, **kwargs) -> AsyncMock:\n",
    "#     response = Mock()\n",
    "#     response.status_code = 200\n",
    "#     response.json = Mock(return_value=predict(request=None, payload=PredictPayload(**kwargs['json']))[0].dict())\n",
    "#     return response\n",
    "\n",
    "# async def mock_get_db_model(_, model_name: str):\n",
    "#     class MockModel:\n",
    "#         __table__ = type('MockTable', (), {'columns': [type('MockColumn', (), {'name': name}) for name in model_dict_predefined.keys()]})\n",
    "#         def __init__(self, model_dict):\n",
    "#             for key, value in model_dict.items():\n",
    "#                 setattr(self, key, value)\n",
    "#     return MockModel(model_dict_predefined)\n",
    "\n",
    "# async def mock_get_trigger(*args, **kwargs):\n",
    "#     return \"mock_trigger\"\n",
    "\n",
    "# class MockLayer:\n",
    "#     def __init__(self, short_name):\n",
    "#         self.short_name = short_name\n",
    "\n",
    "# async def mock_get_layer(self, layer, **kwargs):\n",
    "#     return MockLayer(short_name=layer)\n",
    "\n",
    "# async def mock_get_sentinel1_grd(*args, **kwargs):\n",
    "#     return \"mock_sentinel1_grd\"\n",
    "\n",
    "# async def mock_deactivate_stale_slicks_from_scene_id(*args, **kwargs):\n",
    "#     return 0\n",
    "\n",
    "# class MockOrchestratorRun:\n",
    "#     def __init__(self):\n",
    "#         self.success = True\n",
    "\n",
    "# async def mock_add_orchestrator(*args, **kwargs):\n",
    "#     return MockOrchestratorRun()\n",
    "\n",
    "# with\\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.get_db_model', new=mock_get_db_model), \\\n",
    "#     patch('httpx.AsyncClient.post', new=mock_post), \\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.get_trigger', new=mock_get_trigger), \\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.get_layer', new=mock_get_layer), \\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.get_sentinel1_grd', new=mock_get_sentinel1_grd), \\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.deactivate_stale_slicks_from_scene_id', new=mock_deactivate_stale_slicks_from_scene_id), \\\n",
    "#     patch('cerulean_cloud.database_client.DatabaseClient.add_orchestrator', new=mock_add_orchestrator):\n",
    "\n",
    "#     response = await _orchestrate(\n",
    "#         payload, \n",
    "#         get_tiler(), \n",
    "#         get_titiler_client(), \n",
    "#         get_roda_sentinelhub_client(), \n",
    "#         get_database_engine()\n",
    "#     )\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_titiler_client_and_offset_tiles(sentinel_scene, offset=.33):\n",
    "    payload = OrchestratorInput(**sentinel_scene)\n",
    "    TitilerClient_url = os.getenv('TITILER_URL')\n",
    "    titiler_client = TitilerClient(url=TitilerClient_url)\n",
    "    scene_bounds = await titiler_client.get_bounds(payload.sceneid)\n",
    "    tiler = TMS\n",
    "    base_tiles = list(tiler.tiles(*scene_bounds, [payload.zoom], truncate=False))\n",
    "    offset_tile_bounds = offset_bounds_from_base_tiles(base_tiles, offset_amount=offset)\n",
    "    return titiler_client, offset_tile_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = \"S1A_IW_GRDH_1SDV_20240204T184243_20240204T184308_052413_0656A2_1B88\"\n",
    "test_scene = {\"sceneid\": scene_id , \"zoom\":9, \"scale\":2}\n",
    "\n",
    "titler_client , tile_bounds =  await get_titiler_client_and_offset_tiles(test_scene,offset=.66)\n",
    "\n",
    "example_tile_37 = tile_bounds[37] # 37 and 45\n",
    "example_tile_45 = tile_bounds[45] # 37 and 45\n",
    "\n",
    "vv_37 = (await titler_client.get_offset_tile(scene_id, *example_tile_37,height=512,width=512)).transpose(2,0,1)[0]\n",
    "vv_45 = (await titler_client.get_offset_tile(scene_id, *example_tile_45,height=512,width=512)).transpose(2,0,1)[0]\n",
    "\n",
    "plt.imshow(vv_37, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_stack = [\n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_37]*len(model_dict_predefined[\"layers\"]))), bounds=example_tile_37), \n",
    "    InferenceInput(image=img_array_to_b64_image(np.array([vv_45]*len(model_dict_predefined[\"layers\"]))), bounds=example_tile_45),\n",
    "    ]\n",
    "\n",
    "model = get_model(model_dict_predefined,model_path_local=MODEL_PATH_LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(inf_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(out)==2:\n",
    "#     # i.e. If you have edited models.py to return inference_result_stack, raw_preds\n",
    "\n",
    "#     inference_result_stack, raw_preds = out\n",
    "\n",
    "#     # Take softmax along the channel dimension (dim=1)\n",
    "#     softmax_tensor = F.softmax(raw_preds, dim=1)\n",
    "#     # Take the argmax along the channel dimension to get the predicted classes\n",
    "#     argmax_tensor = torch.argmax(softmax_tensor, dim=1)\n",
    "#     # Convert tensor to numpy array for visualization\n",
    "#     argmax_numpy = argmax_tensor.squeeze().numpy()\n",
    "\n",
    "#     cls_map = model_dict_predefined[\"cls_map\"]\n",
    "#     # Generate colormap and norm for visualization\n",
    "#     colors = plt.cm.tab20(np.linspace(0, 1, len(cls_map)))\n",
    "#     cmap, norm = ListedColormap(colors), plt.Normalize(vmin=-0.5, vmax=len(cls_map)-0.5)\n",
    "\n",
    "#     # Plot the argmax results as an image\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(argmax_numpy, cmap=cmap, norm=norm)\n",
    "\n",
    "#     # Create and display custom legend\n",
    "#     handles = [mpatches.Patch(color=colors[i], label=cls_map[i]) for i in cls_map]\n",
    "#     plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize='large')\n",
    "#     plt.title(\"Class Prediction\", fontsize=16)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_dict_predefined,model_path_local=MODEL_PATH_LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "gj = model.postprocess_tileset([out])\n",
    "gdf = gpd.GeoDataFrame.from_features(gj[\"features\"])\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'gdf' is your GeoDataFrame and 'vv_37' is your image array\n",
    "plt.figure(figsize=(10, 10))  # Set the size of the figure (adjust as needed)\n",
    "\n",
    "# Loop through each feature in the GeoDataFrame\n",
    "for index, row in gdf.iterrows():\n",
    "    plt.imshow(vv_37, cmap='gray')  # Display the image\n",
    "    # Plot the feature on top of the image\n",
    "    gdf.iloc[[index]].plot(ax=plt.gca(), alpha=0.5, edgecolor='red', facecolor='none')\n",
    "    plt.title(f'Class: {model_dict_predefined[\"cls_map\"][row[\"inf_idx\"]]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, t = model.stitch(out)\n",
    "argmax_indices = np.argmax(a, axis=0)\n",
    "\n",
    "# Plot the argmax indices\n",
    "plt.imshow(argmax_indices, cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
