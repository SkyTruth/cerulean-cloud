{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_path = os.getenv(\"GIT_FOLDER\")\n",
    "cv3_path = os.getenv(\"CV3_FOLDER\") \n",
    "sys.path.append(git_path)\n",
    "sys.path.append(cv3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerulean_cloud.cloud_function_asa.utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitl_ground_truth_ranks(df, source_type, coll_column = 'collated_score'):\n",
    "    \"\"\"\n",
    "    Calculate the ranks from an hitl df\n",
    "    \"\"\"\n",
    "    true_rank = []\n",
    "    for slick_id, group in df.groupby('slick'):\n",
    "        group.sort_values(by=coll_column, ascending=False, inplace=True)\n",
    "        group['calculated_rank'] = list(range(1,len(group)+1))\n",
    "        true_source = group[group['hitl_verification']==True]\n",
    "        if len(true_source)!=1:\n",
    "            continue\n",
    "            # raise BaseException(\"can't have more than one true source per slick\")\n",
    "\n",
    "        calc_rank = true_source['calculated_rank'].values[0]\n",
    "        if true_source['type'].values[0]==source_type:\n",
    "            true_rank.append(calc_rank)\n",
    "    return true_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj_coll_ranks(hitl_df,mean_adjustments, std_adjustments, fixed_source_type,adjusted_source_type,fixed_mean,fixed_std):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates various rankings and top_3 rates of two source types \n",
    "    by fixing the collation parameters of one source and adjusting the collation parameters\n",
    "    of the other source.\n",
    "\n",
    "    Returns four sets of 3d datapoints\n",
    "    \"\"\"\n",
    "    adjusted_ranking_dps = [] \n",
    "    fixed_ranking_dps = []\n",
    "    adjusted_top_3_dps = []\n",
    "    fixed_top_3_dps = []\n",
    "\n",
    "    # Wrap outer loop with tqdm for progress bar\n",
    "    for mean_adjust in tqdm(mean_adjustments, desc=\"Adjusting Infra Mean\"):\n",
    "        for std_adjust in tqdm(std_adjustments, desc=\"Adjusting Infra Std\", leave=False):\n",
    "            custom_coll_scores = []\n",
    "            for source in hitl_df.iloc:\n",
    "                m, s = (fixed_mean, fixed_std) if source['type'] == fixed_source_type else (mean_adjust, std_adjust)\n",
    "                custom_coll_scores.append((source['coincidence_score'] - m) / s)\n",
    "            hitl_df['custom_coll_score'] = custom_coll_scores\n",
    "            # adjusted_type_list = hitl_df[hitl_df['type'] == 2][hitl_df['hitl_verification'] == True]  # Filtered infra list\n",
    "            # fixed_type_list = hitl_df[hitl_df['type'] == 1][hitl_df['hitl_verification'] == True]  # Filtered vessel list\n",
    "\n",
    "            fixed_type_true_rank = hitl_ground_truth_ranks(hitl_df, fixed_source_type, coll_column='custom_coll_score')\n",
    "            adjusted_type_true_rank = hitl_ground_truth_ranks(hitl_df, adjusted_source_type, coll_column='custom_coll_score')\n",
    "\n",
    "            # Append ranking data points\n",
    "            adjusted_ranking_dps.append((mean_adjust, std_adjust, np.mean(adjusted_type_true_rank)))\n",
    "            fixed_ranking_dps.append((mean_adjust, std_adjust, np.mean(fixed_type_true_rank)))\n",
    "\n",
    "            fixed_top_3_dps.append((mean_adjust, std_adjust, np.sum(np.array(fixed_type_true_rank)<=3) / len(fixed_type_true_rank)))\n",
    "            adjusted_top_3_dps.append((mean_adjust, std_adjust, np.sum(np.array(adjusted_type_true_rank)<=3) / len(adjusted_type_true_rank)))\n",
    "\n",
    "    return adjusted_ranking_dps, adjusted_top_3_dps, fixed_ranking_dps, fixed_top_3_dps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_optimal_rankings_dp(fix_ranking_dps, adj_ranking_dps, fix_type=\"Vessel\", adj_type=\"Infra\"):\n",
    "    \"\"\"\n",
    "    Search for optimal mean and std for ranking\n",
    "    \"\"\"\n",
    "    max_ranking_dps = []\n",
    "    for i in range(len(adj_ranking_dps)):\n",
    "        x = adj_ranking_dps[i][0]\n",
    "        y = adj_ranking_dps[i][1]\n",
    "        max_ranking_dps.append([x,y,max(adj_ranking_dps[i][2], fix_ranking_dps[i][2])])\n",
    "\n",
    "    minimum = 5\n",
    "    for i in range(len(max_ranking_dps)):\n",
    "        rank = max_ranking_dps[i][2]\n",
    "        # print(rank)\n",
    "        if rank < minimum:\n",
    "            minimum = rank\n",
    "            mean = max_ranking_dps[i][0]\n",
    "            std = max_ranking_dps[i][1]\n",
    "            min_fix_ranking = fix_ranking_dps[i][2]\n",
    "            min_adj_ranking = adj_ranking_dps[i][2]\n",
    "\n",
    "    print(\"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\", round(mean,3),\"MEAN AND\", round(std,3), \"STD\")\n",
    "    print(f\"With {fix_type} avg ranking:\", min_fix_ranking)\n",
    "    print(f\"With {adj_type} avg ranking:\", min_adj_ranking)\n",
    "\n",
    "    return (mean,std,minimum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_optimal_top_3_dp(fix_top_3_dps, adj_top_3_dps, fix_type=\"Vessel\", adj_type=\"Infra\"):\n",
    "    \"\"\"\n",
    "    Search for optimal mean and std for top 3 rate \n",
    "    \"\"\"\n",
    "    min_top_3_dps = []\n",
    "    for i in range(len(adj_top_3_dps)):\n",
    "        x = adj_top_3_dps[i][0]\n",
    "        y = adj_top_3_dps[i][1]\n",
    "        min_top_3_dps.append([x,y,min(adj_top_3_dps[i][2], fix_top_3_dps[i][2])])\n",
    "\n",
    "    maximum = 0\n",
    "    for i in range(len(min_top_3_dps)):\n",
    "        bot = min_top_3_dps[i][2]\n",
    "        # print(rank)\n",
    "        if bot > maximum:\n",
    "            maximum = bot\n",
    "            mean = min_top_3_dps[i][0]\n",
    "            std = min_top_3_dps[i][1]\n",
    "            min_fix_top_3 = fix_top_3_dps[i][2]\n",
    "            min_adj_top_3 = adj_top_3_dps[i][2]\n",
    "\n",
    "    print(\"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\", round(mean,3),\"MEAN AND\", round(std,3), \"STD\")\n",
    "    print(f\"With {fix_type} top 3 rate:\", min_fix_top_3)\n",
    "    print(f\"With {adj_type} top 3 rate:\", min_adj_top_3)\n",
    "\n",
    "    return (mean,std,maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dps_3d(dps1,dps2, opt_point = None,metric = \"Ranking\", source_type1 = \"Vessel\", source_type2 = \"Infra\"):\n",
    "    # First set of points\n",
    "    x1, y1, z1 = np.array(dps1).transpose(1,0)\n",
    "\n",
    "    # Second set of points\n",
    "    x2, y2, z2 = np.array(dps2).transpose(1,0)\n",
    "\n",
    "    # Create the figure and add traces\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Infra Avg Ranking\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x1, y=y1, z=z1,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=z1,  # Use z-values for color\n",
    "            colorscale='Blues',  # Gradient scale\n",
    "            opacity=1.0\n",
    "        ),\n",
    "        name=f'{source_type1} Average {metric}'\n",
    "    ))\n",
    "\n",
    "    # Vessel Avg Ranking\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x2, y=y2, z=z2,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=z2,  # Use z-values for color\n",
    "            colorscale='Reds',\n",
    "            opacity=1.0\n",
    "        ),\n",
    "        name=f'{source_type2} Avg {metric}'\n",
    "    ))\n",
    "\n",
    "    # Optimized Point\n",
    "    if not opt_point is None:\n",
    "        mean = opt_point[0]\n",
    "        std = opt_point[1]\n",
    "        minimum = opt_point[2]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[mean], y=[std], z=[minimum],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='green',\n",
    "                opacity=1.0\n",
    "            ),\n",
    "            name='Optimized Point'\n",
    "        ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='Mean Adjustment',\n",
    "            yaxis_title='Std Adjustment',\n",
    "            zaxis_title=f'Avg {metric}',\n",
    "            aspectratio=dict(x=1, y=1, z=1.0)\n",
    "        ),\n",
    "        title=f'Z (Average {metric}) at various X (mean adjustment) and Y (std adjustmentment)',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load hitl dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'C:\\Users\\ebeva\\SkyTruth\\cv3\\slick_to_source dump 2024-12-31.csv'\n",
    "hitl_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MEAN and STD from coincidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = hitl_df[hitl_df['type']==2][hitl_df['hitl_verification']==True]#['coincidence_score'].values\n",
    "vess_list = hitl_df[hitl_df['type']==1][hitl_df['hitl_verification']==True]#['coincidence_score'].values\n",
    "INFRA_COIN = infra_list['coincidence_score'].values\n",
    "VESS_COIN = vess_list['coincidence_score'].values\n",
    "NEW_INFRA_MEAN, NEW_INFRA_STD = np.mean(INFRA_COIN), np.std(INFRA_COIN)\n",
    "NEW_VESSEL_MEAN, NEW_VESSEL_STD = np.mean(VESS_COIN), np.std(VESS_COIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFRA MEAN:\", INFRA_MEAN, \"--->\", NEW_INFRA_MEAN)\n",
    "print(\"INFRA STD:\", INFRA_STD, \"--->\", NEW_INFRA_STD)\n",
    "print(\"VESSEL_MEAN:\", VESSEL_MEAN, \"--->\", NEW_VESSEL_MEAN)\n",
    "print(\"VESSEL_STD:\", VESSEL_STD, \"--->\", NEW_VESSEL_STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics at varying collations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculate collated score by adjusting infra distributions\")\n",
    "\n",
    "infra_mean_adjustments = list(np.arange(0, .9, 0.025))\n",
    "infra_std_adjustments = list(np.arange(0.0, 0.5, 0.01))\n",
    "\n",
    "infra_ranking_dps, infra_top_3_dps, vessel_ranking_dps, vessel_top_3_dps = calculate_adj_coll_ranks(\n",
    "    hitl_df=hitl_df,\n",
    "    mean_adjustments=infra_mean_adjustments,\n",
    "    std_adjustments=infra_std_adjustments,\n",
    "    fixed_source_type=1,\n",
    "    adjusted_source_type=2,\n",
    "    fixed_mean=NEW_VESSEL_MEAN,\n",
    "    fixed_std=NEW_VESSEL_STD\n",
    "                                                                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal values and display 3D mean std charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_point = search_optimal_rankings_dp(fix_ranking_dps=vessel_ranking_dps, adj_ranking_dps=infra_ranking_dps)\n",
    "plot_dps_3d(infra_ranking_dps, vessel_ranking_dps, opt_point=opt_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_point = search_optimal_top_3_dp(fix_top_3_dps=vessel_top_3_dps, adj_top_3_dps=infra_top_3_dps)\n",
    "plot_dps_3d(infra_top_3_dps, vessel_top_3_dps, opt_point=opt_point, metric='Top 3 Source Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify absolute mean and std of collation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = hitl_df[hitl_df['type']==2][hitl_df['hitl_verification']==True]#['coincidence_score'].values\n",
    "vess_list = hitl_df[hitl_df['type']==1][hitl_df['hitl_verification']==True]#['coincidence_score'].\n",
    "\n",
    "print(\"Vessel Collation Score mean and std:\",round(np.mean(vess_list['custom_coll_score']),3), round(np.std(vess_list['custom_coll_score']),3))\n",
    "print(\"Infra Collation Score mean and std\",round(np.mean(infra_list['custom_coll_score']),3), round(np.std(infra_list['custom_coll_score']),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
