{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_path = os.getenv(\"GIT_FOLDER\")\n",
    "cv3_path = os.getenv(\"CV3_FOLDER\")\n",
    "sys.path.append(git_path)\n",
    "sys.path.append(cv3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerulean_cloud.cloud_function_asa.utils.constants import (\n",
    "    INFRA_MEAN,\n",
    "    INFRA_STD,\n",
    "    VESSEL_MEAN,\n",
    "    VESSEL_STD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitl_ground_truth_ranks(df, source_type, coll_column=\"collated_score\"):\n",
    "    \"\"\"\n",
    "    Calculate the ranks from an hitl df\n",
    "    \"\"\"\n",
    "    true_rank = []\n",
    "    for slick_id, group in df.groupby(\"slick\"):\n",
    "        group.sort_values(by=coll_column, ascending=False, inplace=True)\n",
    "        group[\"calculated_rank\"] = list(range(1, len(group) + 1))\n",
    "        true_source = group[group[\"hitl_verification\"]]\n",
    "        if len(true_source) != 1:\n",
    "            continue\n",
    "            # raise BaseException(\"can't have more than one true source per slick\")\n",
    "\n",
    "        calc_rank = true_source[\"calculated_rank\"].values[0]\n",
    "        if true_source[\"type\"].values[0] == source_type:\n",
    "            true_rank.append(calc_rank)\n",
    "    return true_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj_coll_ranks(\n",
    "    hitl_df,\n",
    "    mean_adjustments,\n",
    "    std_adjustments,\n",
    "    fixed_source_type,\n",
    "    adjusted_source_type,\n",
    "    fixed_mean,\n",
    "    fixed_std,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates various rankings and top_3 rates of two source types\n",
    "    by fixing the collation parameters of one source and adjusting the collation parameters\n",
    "    of the other source.\n",
    "\n",
    "    Returns four sets of 3d datapoints\n",
    "    \"\"\"\n",
    "    adjusted_ranking_dps = []\n",
    "    fixed_ranking_dps = []\n",
    "    adjusted_top_3_dps = []\n",
    "    fixed_top_3_dps = []\n",
    "\n",
    "    # Wrap outer loop with tqdm for progress bar\n",
    "    for mean_adjust in tqdm(mean_adjustments, desc=\"Adjusting Infra Mean\"):\n",
    "        for std_adjust in tqdm(\n",
    "            std_adjustments, desc=\"Adjusting Infra Std\", leave=False\n",
    "        ):\n",
    "            custom_coll_scores = []\n",
    "            for source in hitl_df.iloc:\n",
    "                m, s = (\n",
    "                    (fixed_mean, fixed_std)\n",
    "                    if source[\"type\"] == fixed_source_type\n",
    "                    else (mean_adjust, std_adjust)\n",
    "                )\n",
    "                custom_coll_scores.append((source[\"coincidence_score\"] - m) / s)\n",
    "            hitl_df[\"custom_coll_score\"] = custom_coll_scores\n",
    "            # adjusted_type_list = hitl_df[hitl_df['type'] == 2][hitl_df['hitl_verification']]  # Filtered infra list\n",
    "            # fixed_type_list = hitl_df[hitl_df['type'] == 1][hitl_df['hitl_verification']]  # Filtered vessel list\n",
    "\n",
    "            fixed_type_true_rank = hitl_ground_truth_ranks(\n",
    "                hitl_df, fixed_source_type, coll_column=\"custom_coll_score\"\n",
    "            )\n",
    "            adjusted_type_true_rank = hitl_ground_truth_ranks(\n",
    "                hitl_df, adjusted_source_type, coll_column=\"custom_coll_score\"\n",
    "            )\n",
    "\n",
    "            # Append ranking data points\n",
    "            adjusted_ranking_dps.append(\n",
    "                (mean_adjust, std_adjust, np.mean(adjusted_type_true_rank))\n",
    "            )\n",
    "            fixed_ranking_dps.append(\n",
    "                (mean_adjust, std_adjust, np.mean(fixed_type_true_rank))\n",
    "            )\n",
    "\n",
    "            fixed_top_3_dps.append(\n",
    "                (\n",
    "                    mean_adjust,\n",
    "                    std_adjust,\n",
    "                    np.sum(np.array(fixed_type_true_rank) <= 3)\n",
    "                    / len(fixed_type_true_rank),\n",
    "                )\n",
    "            )\n",
    "            adjusted_top_3_dps.append(\n",
    "                (\n",
    "                    mean_adjust,\n",
    "                    std_adjust,\n",
    "                    np.sum(np.array(adjusted_type_true_rank) <= 3)\n",
    "                    / len(adjusted_type_true_rank),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return adjusted_ranking_dps, adjusted_top_3_dps, fixed_ranking_dps, fixed_top_3_dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_optimal_rankings_dp(\n",
    "    fix_ranking_dps, adj_ranking_dps, fix_type=\"Vessel\", adj_type=\"Infra\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for optimal mean and std for ranking\n",
    "    \"\"\"\n",
    "    max_ranking_dps = []\n",
    "    for i in range(len(adj_ranking_dps)):\n",
    "        x = adj_ranking_dps[i][0]\n",
    "        y = adj_ranking_dps[i][1]\n",
    "        max_ranking_dps.append(\n",
    "            [x, y, max(adj_ranking_dps[i][2], fix_ranking_dps[i][2])]\n",
    "        )\n",
    "\n",
    "    minimum = 5\n",
    "    for i in range(len(max_ranking_dps)):\n",
    "        rank = max_ranking_dps[i][2]\n",
    "        # print(rank)\n",
    "        if rank < minimum:\n",
    "            minimum = rank\n",
    "            mean = max_ranking_dps[i][0]\n",
    "            std = max_ranking_dps[i][1]\n",
    "            min_fix_ranking = fix_ranking_dps[i][2]\n",
    "            min_adj_ranking = adj_ranking_dps[i][2]\n",
    "\n",
    "    print(\n",
    "        \"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\",\n",
    "        round(mean, 3),\n",
    "        \"MEAN AND\",\n",
    "        round(std, 3),\n",
    "        \"STD\",\n",
    "    )\n",
    "    print(f\"With {fix_type} avg ranking:\", min_fix_ranking)\n",
    "    print(f\"With {adj_type} avg ranking:\", min_adj_ranking)\n",
    "\n",
    "    return (mean, std, minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_optimal_top_3_dp(\n",
    "    fix_top_3_dps, adj_top_3_dps, fix_type=\"Vessel\", adj_type=\"Infra\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for optimal mean and std for top 3 rate\n",
    "    \"\"\"\n",
    "    min_top_3_dps = []\n",
    "    for i in range(len(adj_top_3_dps)):\n",
    "        x = adj_top_3_dps[i][0]\n",
    "        y = adj_top_3_dps[i][1]\n",
    "        min_top_3_dps.append([x, y, min(adj_top_3_dps[i][2], fix_top_3_dps[i][2])])\n",
    "\n",
    "    maximum = 0\n",
    "    for i in range(len(min_top_3_dps)):\n",
    "        bot = min_top_3_dps[i][2]\n",
    "        # print(rank)\n",
    "        if bot > maximum:\n",
    "            maximum = bot\n",
    "            mean = min_top_3_dps[i][0]\n",
    "            std = min_top_3_dps[i][1]\n",
    "            min_fix_top_3 = fix_top_3_dps[i][2]\n",
    "            min_adj_top_3 = adj_top_3_dps[i][2]\n",
    "\n",
    "    print(\n",
    "        \"IDEAL MEAN AND STD ADJUSTMENT FOUND AT\",\n",
    "        round(mean, 3),\n",
    "        \"MEAN AND\",\n",
    "        round(std, 3),\n",
    "        \"STD\",\n",
    "    )\n",
    "    print(f\"With {fix_type} top 3 rate:\", min_fix_top_3)\n",
    "    print(f\"With {adj_type} top 3 rate:\", min_adj_top_3)\n",
    "\n",
    "    return (mean, std, maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dps_3d(\n",
    "    dps1,\n",
    "    dps2,\n",
    "    opt_point=None,\n",
    "    metric=\"Ranking\",\n",
    "    source_type1=\"Vessel\",\n",
    "    source_type2=\"Infra\",\n",
    "):\n",
    "    # First set of points\n",
    "    x1, y1, z1 = np.array(dps1).transpose(1, 0)\n",
    "\n",
    "    # Second set of points\n",
    "    x2, y2, z2 = np.array(dps2).transpose(1, 0)\n",
    "\n",
    "    # Create the figure and add traces\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Infra Avg Ranking\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=x1,\n",
    "            y=y1,\n",
    "            z=z1,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=z1,  # Use z-values for color\n",
    "                colorscale=\"Blues\",  # Gradient scale\n",
    "                opacity=1.0,\n",
    "            ),\n",
    "            name=f\"{source_type1} Average {metric}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Vessel Avg Ranking\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=x2,\n",
    "            y=y2,\n",
    "            z=z2,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=z2,  # Use z-values for color\n",
    "                colorscale=\"Reds\",\n",
    "                opacity=1.0,\n",
    "            ),\n",
    "            name=f\"{source_type2} Avg {metric}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Optimized Point\n",
    "    if opt_point is not None:\n",
    "        mean = opt_point[0]\n",
    "        std = opt_point[1]\n",
    "        minimum = opt_point[2]\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[mean],\n",
    "                y=[std],\n",
    "                z=[minimum],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=10, color=\"green\", opacity=1.0),\n",
    "                name=\"Optimized Point\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=\"Mean Adjustment\",\n",
    "            yaxis_title=\"Std Adjustment\",\n",
    "            zaxis_title=f\"Avg {metric}\",\n",
    "            aspectratio=dict(x=1, y=1, z=1.0),\n",
    "        ),\n",
    "        title=f\"Z (Average {metric}) at various X (mean adjustment) and Y (std adjustmentment)\",\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load hitl dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = cv3_path + \"asa_analysis/evaluation/slick_to_source dump 2024-12-31.csv\"\n",
    "hitl_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MEAN and STD from coincidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = hitl_df[hitl_df[\"type\"] == 2][\n",
    "    hitl_df[\"hitl_verification\"]\n",
    "]  # ['coincidence_score'].values\n",
    "vess_list = hitl_df[hitl_df[\"type\"] == 1][\n",
    "    hitl_df[\"hitl_verification\"]\n",
    "]  # ['coincidence_score'].values\n",
    "INFRA_COIN = infra_list[\"coincidence_score\"].values\n",
    "VESS_COIN = vess_list[\"coincidence_score\"].values\n",
    "NEW_INFRA_MEAN, NEW_INFRA_STD = np.mean(INFRA_COIN), np.std(INFRA_COIN)\n",
    "NEW_VESSEL_MEAN, NEW_VESSEL_STD = np.mean(VESS_COIN), np.std(VESS_COIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFRA MEAN:\", INFRA_MEAN, \"--->\", NEW_INFRA_MEAN)\n",
    "print(\"INFRA STD:\", INFRA_STD, \"--->\", NEW_INFRA_STD)\n",
    "print(\"VESSEL_MEAN:\", VESSEL_MEAN, \"--->\", NEW_VESSEL_MEAN)\n",
    "print(\"VESSEL_STD:\", VESSEL_STD, \"--->\", NEW_VESSEL_STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics at varying collations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculate collated score by adjusting infra distributions\")\n",
    "\n",
    "infra_mean_adjustments = list(np.arange(0, 0.9, 0.025))\n",
    "infra_std_adjustments = list(np.arange(0.0, 0.5, 0.01))\n",
    "\n",
    "infra_ranking_dps, infra_top_3_dps, vessel_ranking_dps, vessel_top_3_dps = (\n",
    "    calculate_adj_coll_ranks(\n",
    "        hitl_df=hitl_df,\n",
    "        mean_adjustments=infra_mean_adjustments,\n",
    "        std_adjustments=infra_std_adjustments,\n",
    "        fixed_source_type=1,\n",
    "        adjusted_source_type=2,\n",
    "        fixed_mean=NEW_VESSEL_MEAN,\n",
    "        fixed_std=NEW_VESSEL_STD,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal values and display 3D mean std charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_point = search_optimal_rankings_dp(\n",
    "    fix_ranking_dps=vessel_ranking_dps, adj_ranking_dps=infra_ranking_dps\n",
    ")\n",
    "plot_dps_3d(infra_ranking_dps, vessel_ranking_dps, opt_point=opt_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_point = search_optimal_top_3_dp(\n",
    "    fix_top_3_dps=vessel_top_3_dps, adj_top_3_dps=infra_top_3_dps\n",
    ")\n",
    "plot_dps_3d(\n",
    "    infra_top_3_dps, vessel_top_3_dps, opt_point=opt_point, metric=\"Top 3 Source Rate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify absolute mean and std of collation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_list = hitl_df[hitl_df[\"type\"] == 2][\n",
    "    hitl_df[\"hitl_verification\"]\n",
    "]  # ['coincidence_score'].values\n",
    "vess_list = hitl_df[hitl_df[\"type\"] == 1][\n",
    "    hitl_df[\"hitl_verification\"]\n",
    "]  # ['coincidence_score'].\n",
    "\n",
    "print(\n",
    "    \"Vessel Collation Score mean and std:\",\n",
    "    round(np.mean(vess_list[\"custom_coll_score\"]), 3),\n",
    "    round(np.std(vess_list[\"custom_coll_score\"]), 3),\n",
    ")\n",
    "print(\n",
    "    \"Infra Collation Score mean and std\",\n",
    "    round(np.mean(infra_list[\"custom_coll_score\"]), 3),\n",
    "    round(np.std(infra_list[\"custom_coll_score\"]), 3),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceru202411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
