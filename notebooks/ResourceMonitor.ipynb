{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52c381e-6a2e-4936-ab41-0b16d2d98aaa",
   "metadata": {},
   "source": [
    "# Show resource allocations and logs on a plot\n",
    "\n",
    "**Note:** you must install `google-cloud-monitoring` to use this, otherwise, comment out the import monitoring_v3 and fetch_memory_usage lines and set mem_time and mem_y to None in plot_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692138d7-d36d-47cf-bd02-b9259f0b3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from google.cloud import monitoring_v3\n",
    "from google.protobuf import duration_pb2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent / 'cerulean_cloud') + \"/\")\n",
    "from structured_logger import (\n",
    "    log_query,\n",
    "    query_logger,\n",
    "    generate_log_file,\n",
    "    get_scene_log_stats,\n",
    "    get_latest_revision,\n",
    ")\n",
    "\n",
    "project_id = \"cerulean-338116\"\n",
    "service_name = \"cerulean-cloud-test-cr-orchestrator\"\n",
    "revision_name = \"cerulean-cloud-test-cr-orchestrator-00119-pw6\"\n",
    "# revision_name = get_latest_revision(project_id, service_name)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "end_time = now+datetime.timedelta(days=1)\n",
    "start_time = now - datetime.timedelta(days=2)  # N days ago\n",
    "# end_time = datetime.datetime(2025,2,8,0,0)\n",
    "# start_time = datetime.datetime(2025,2,5,0,0)\n",
    "tz_local = \"US/Arizona\"\n",
    "\n",
    "project_name = f\"projects/{project_id}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adca7c1-f23e-4ca6-b52e-82562b1c8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_memory_usage(revision_name, start_time, end_time, interval_min=5):\n",
    "    \"\"\"\n",
    "    Fetch Cloud Run memory usage over the last 3 days.\n",
    "    \"\"\"\n",
    "    metric_type = \"run.googleapis.com/container/memory/utilizations\"\n",
    "    \n",
    "    # Define query filter\n",
    "    filt = f'''\n",
    "        metric.type = \"{metric_type}\"\n",
    "        AND resource.labels.revision_name = \"{revision_name}\"\n",
    "    '''\n",
    "    \n",
    "    # Define aggregation settings\n",
    "    aggregation=monitoring_v3.Aggregation(\n",
    "        alignment_period=duration_pb2.Duration(seconds=interval_min*60),\n",
    "        per_series_aligner=monitoring_v3.Aggregation.Aligner.ALIGN_PERCENTILE_50 \n",
    "    )\n",
    "\n",
    "    # Define query request\n",
    "    query = monitoring_v3.ListTimeSeriesRequest(\n",
    "        name=project_name,\n",
    "        filter=filt,\n",
    "        interval=monitoring_v3.TimeInterval(start_time=start_time, end_time=end_time),\n",
    "        aggregation=aggregation,\n",
    "        view=monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize Cloud Monitoring client\n",
    "        client = monitoring_v3.MetricServiceClient()\n",
    "        results = client.list_time_series(query)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching memory usage for revision {revision_name}: {e}\")\n",
    "        return pd.DataFrame(columns=[\"timestamp\", \"memory_usage\"])  # Return empty dataframe\n",
    "\n",
    "    # Extract data points\n",
    "    data = []\n",
    "    for result in results:\n",
    "        for point in result.points:\n",
    "            timestamp = point.interval.end_time\n",
    "            value = point.value.double_value if hasattr(point.value, \"double_value\") else None\n",
    "            data.append([timestamp, value])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"timestamp\", \"memory_usage\"])\n",
    "\n",
    "\n",
    "\n",
    "def interp_logs_to_mem_ts(mem_ts, log_ts, mem):\n",
    "    # Create interpolation function\n",
    "    interp_func = interp1d(\n",
    "        mem_ts.astype(np.int64) / 10**9,  # Convert timestamps to seconds\n",
    "        mem,\n",
    "        kind=\"linear\", \n",
    "        fill_value=\"extrapolate\" \n",
    "    )\n",
    "    \n",
    "    return interp_func(log_ts.astype(np.int64) / 10**9)\n",
    "\n",
    "\n",
    "def add_trace_hover(fig, df, size, color, name):\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], \n",
    "        y=df['y'], \n",
    "        mode='markers', \n",
    "        marker=dict(size=size, color=color),\n",
    "        text=df['text'], \n",
    "        name=name,\n",
    "        hoverinfo='text',\n",
    "    ))\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def add_severity_trace(fig, logs):\n",
    "\n",
    "    severities = [\"INFO\",\"WARNING\",\"ERROR\", \"DEBUG\"]\n",
    "    colors = [\"blue\", \"orange\", \"red\", \"green\"]\n",
    "    sizes = [3, 5, 10]\n",
    "\n",
    "    \n",
    "    tmp = logs[logs['mem_usage'].isnull()==False]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp['timestamp'], \n",
    "        y=tmp['y'], \n",
    "        mode='lines',\n",
    "        line=dict(color='gray', width=1, dash='dash'),\n",
    "        name=\"Memory Usage\",\n",
    "        hoverinfo='skip' \n",
    "    ))\n",
    "\n",
    "    for severity, color, size in zip(severities, colors, sizes):\n",
    "\n",
    "        tmp = logs[logs['severity']==severity]\n",
    "        fig = add_trace_hover(fig, tmp, size, color, name=severity)\n",
    "        \n",
    "    return fig\n",
    "\n",
    "def add_initiating_orchestrator_trace(fig, logs, size=5, color=\"green\"):\n",
    "    tmp = logs[logs['message'].str.contains(\"initiating orchestrator\",case=False, na=False)]\n",
    "    fig = add_trace_hover(fig, tmp, size, color, name=\"orchestrator initiaion\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_memory_usage(mem_time=None, mem_y=None, logs=None, plot_type=\"matplotlib\", label=\"Memory Usage (%)\"):\n",
    "    if plot_type == \"matplotlib\":\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df_mem[\"timestamp\"].dt.tz_convert(\"US/Arizona\"), df_mem[\"memory_usage\"], label=label)\n",
    "        plt.xlabel(\"Timestamp\")\n",
    "        plt.ylabel(\"Memory Usage (bytes)\")\n",
    "        plt.title(f\"Cloud Run Memory Usage for {revision_name}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    elif plot_type ==\"plotly\":\n",
    "        # Create Scatter Plot with Clickable Points\n",
    "        fig = go.Figure()\n",
    "\n",
    "        if mem_time is not None:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=mem_time, \n",
    "                y=mem_y, \n",
    "                mode='lines',\n",
    "                line=dict(color='black', width=2, dash='solid'), \n",
    "                name=\"Memory Usage\",\n",
    "                hoverinfo='skip' \n",
    "            ))\n",
    "        \n",
    "\n",
    "        if logs is not None:\n",
    "            fig = add_severity_trace(fig, logs)\n",
    "            fig = add_initiating_orchestrator_trace(fig, logs, size=8, color=\"cyan\")\n",
    "            \n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=label,\n",
    "            hovermode=\"closest\",\n",
    "            dragmode=\"zoom\"\n",
    "        )\n",
    "        \n",
    "        fig.show(config={\"scrollZoom\": True})\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb31b01-5587-45c2-98ac-334f4f25ff06",
   "metadata": {},
   "source": [
    "# Plot memory usage and logs\n",
    "\n",
    "**Note:** memory allocation seems to be offset a bit from logs, so to track memory usage, it is best to ensure you are tracking `mem_usage` with the logger, which can be done by setting `track_memory_usage=True` in structured_logger.py<br><br>\n",
    "**Note:** Some of the internal ERRORs (not the ones manually set in the codebase) do not seem to be lined up in time. An end of life event often appears long before the actual event. These will show up on the plot as red points with y=0 on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf31266-5ba2-4edd-a605-96c83c74c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"querying logger\")\n",
    "query = log_query(\n",
    "    service_name,\n",
    "    revision_name=revision_name,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    ")\n",
    "logs = query_logger(project_id, query)\n",
    "logs = logs.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "logs[\"timestamp\"] = logs[\"timestamp\"].dt.tz_convert(tz_local)\n",
    "logs[\"mem_usage\"] = logs['json_payload'].apply(lambda x: x['perc_ram_used']/100 if x is not None and 'perc_ram_used' in x else None)\n",
    "instance_id = logs['instanceId'].unique()[0]\n",
    "\n",
    "print(\"querying metrics\")\n",
    "df_mem = fetch_memory_usage(revision_name, start_time, end_time, interval_min=1)\n",
    "df_mem[\"timestamp\"] = df_mem[\"timestamp\"].dt.tz_convert(tz_local)\n",
    "\n",
    "if len(logs['mem_usage'].dropna()) > 0:\n",
    "    logs['y'] = logs['mem_usage'].fillna(0)\n",
    "else:\n",
    "    logs['y'] = interp_logs_to_mem_ts(df_mem['timestamp'], logs['timestamp'], df_mem[\"memory_usage\"])\n",
    "\n",
    "\n",
    "# Plot Memory Usage\n",
    "if not df_mem.empty:\n",
    "    logs0 = logs.copy()\n",
    "    logs0['text'] = logs0['message']\n",
    "    fig = plot_memory_usage(mem_time=df_mem[\"timestamp\"], mem_y=df_mem[\"memory_usage\"], logs=logs0, plot_type=\"plotly\")\n",
    "else:\n",
    "    print(f\"No memory usage data found for revision {revision_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f515a48-b753-403d-93a5-ec4e76c79d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_log_file(logs, filename=\"log.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
